{
    "id": "c201fbd0a4c8a2f1783e7a96f1f94ad2a4d667ca",
    "meta": {
        "filename": "dod-2013_RDTE_2013_DARPA_MasterJustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2013.zzz_unzipped_MasterJustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2013.xml",
        "budget_year": "2013",
        "budget_cycle": "PB",
        "submission_date": "2012-02",
        "service_agency_name": "Defense Advanced Research Projects Agency",
        "appropriation_code": "0400",
        "appropriation_name": "Research, Development, Test & Evaluation, Defense-Wide"
    },
    "record": {
        "@monetaryUnit": "Millions",
        "ProgramElementNumber": {
            "val": "0603767E"
        },
        "ProgramElementTitle": {
            "val": "SENSOR TECHNOLOGY"
        },
        "R1LineItemNumber": {
            "val": "57"
        },
        "BudgetYear": {
            "val": "2013"
        },
        "BudgetCycle": {
            "val": "PB"
        },
        "SubmissionDate": {
            "val": "2012-02"
        },
        "ServiceAgencyName": {
            "val": "Defense Advanced Research Projects Agency"
        },
        "AppropriationCode": {
            "val": "0400"
        },
        "AppropriationName": {
            "val": "Research, Development, Test & Evaluation, Defense-Wide"
        },
        "BudgetActivityNumber": {
            "val": "3"
        },
        "BudgetActivityTitle": {
            "val": "Advanced Technology Development (ATD)"
        },
        "ProgramElementFunding": {
            "PriorYear": {
                "val": "257.780"
            },
            "CurrentYear": {
                "val": "271.802"
            },
            "BudgetYearOne": {
                "val": "299.438"
            },
            "BudgetYearOneBase": {
                "val": "299.438"
            },
            "BudgetYearOneOCO": {
                "val": "0.000"
            },
            "BudgetYearTwo": {
                "val": "273.605"
            },
            "BudgetYearThree": {
                "val": "276.322"
            },
            "BudgetYearFour": {
                "val": "275.481"
            },
            "BudgetYearFive": {
                "val": "295.392"
            }
        },
        "ProgramElementMissionDescription": {
            "val": "The Sensors Technology program element is budgeted in the Advanced Technology Development Budget Activity because it funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability and battle damage assessment.  \n\nThe Surveillance and Countermeasures Technology project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing and low-cost microelectronics to develop advanced surveillance and targeting systems.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with tactical information needed to succeed in future wars.  Additionally, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats.  \n\nThe Sensors and Processing Systems project develops and demonstrates the advanced sensor processing technologies and systems necessary for the intelligence surveillance and reconnaissance (ISR) mission.  The project is primarily driven by four needs:  1) providing day-night ISR capabilities against the entire range of potential targets; 2) countering camouflage, concealment and deception of mobile ground targets; 3) detecting and identifying objects of interest\/targets across wide geographic areas in near real-time; and 4) enabling reliable identification, precision fire control, tracking, timely engagement and accurate battle damage assessment of ground targets.\n\nThe Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis."
        },
        "ChangeSummary": {
            "PreviousPresidentBudget": {
                "PriorYear": {
                    "val": "205.032"
                },
                "CurrentYear": {
                    "val": "271.802"
                },
                "BudgetYearOne": {
                    "val": "237.238"
                },
                "BudgetYearOneBase": {
                    "val": "237.238"
                },
                "BudgetYearOneOCO": {
                    "val": "0.000"
                }
            },
            "CurrentPresidentBudget": {
                "PriorYear": {
                    "val": "257.780"
                },
                "CurrentYear": {
                    "val": "271.802"
                },
                "BudgetYearOne": {
                    "val": "299.438"
                },
                "BudgetYearOneBase": {
                    "val": "299.438"
                },
                "BudgetYearOneOCO": {
                    "val": "0.000"
                }
            },
            "TotalAdjustments": {
                "PriorYear": {
                    "val": "52.748"
                },
                "CurrentYear": {
                    "val": "0.000"
                },
                "BudgetYearOne": {
                    "val": "62.200"
                },
                "BudgetYearOneBase": {
                    "val": "62.200"
                },
                "BudgetYearOneOCO": {
                    "val": "0.000"
                }
            },
            "AdjustmentDetails": {
                "CongressionalGeneralReductions": {
                    "PriorYear": {
                        "val": "-1.042"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedReductions": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalRescissions": {
                    "PriorYear": {
                        "val": "-10.098"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalAdds": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedTransfers": {
                    "PriorYear": {
                        "val": "64.500"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "Reprogrammings": {
                    "PriorYear": {
                        "val": "5.700"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "SBIRSTTRTransfer": {
                    "PriorYear": {
                        "val": "-6.312"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "OtherAdjustmentDetailList": {
                    "OtherAdjustmentDetail": [
                        {
                            "Title": {
                                "val": "TotalOtherAdjustments"
                            },
                            "Funding": {
                                "BudgetYearOne": {
                                    "val": "62.200"
                                },
                                "BudgetYearOneBase": {
                                    "val": "62.200"
                                },
                                "BudgetYearOneOCO": {
                                    "val": "0.000"
                                }
                            }
                        }
                    ]
                }
            },
            "SummaryExplanation": {
                "val": "FY 2011: Increase reflects internal below threshold reprogrammings and transfers from Army JIEDDO in support of Wide Area Surveillance technology offset by reductions for the Section 8117 Economic Adjustment, rescissons and the SBIR\/STTR transfer. \nFY 2013: Increase reflects additional emphasis on imaging and surveillance technology and classified programs."
            }
        },
        "ProjectList": {
            "Project": [
                {
                    "ProjectNumber": {
                        "val": "SEN-01"
                    },
                    "ProjectTitle": {
                        "val": "SURVEILLANCE AND COUNTERMEASURES TECHNOLOGY"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "29.450"
                        },
                        "CurrentYear": {
                            "val": "38.868"
                        },
                        "BudgetYearOne": {
                            "val": "54.415"
                        },
                        "BudgetYearOneBase": {
                            "val": "54.415"
                        },
                        "BudgetYearOneOCO": {
                            "val": "0.000"
                        },
                        "BudgetYearTwo": {
                            "val": "47.364"
                        },
                        "BudgetYearThree": {
                            "val": "47.965"
                        },
                        "BudgetYearFour": {
                            "val": "47.965"
                        },
                        "BudgetYearFive": {
                            "val": "47.404"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability, and battle damage assessment.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with the tactical information needed to succeed in future wars.  This operational surveillance capability must continue to perform during enemy efforts to deny and deceive the sensor systems, and operate, at times, in a clandestine manner.  This project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing, and low-cost microelectronics to develop advanced surveillance and targeting systems.  In addition, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Adaptable Navigation Systems (ANS)"
                                    },
                                    "Description": {
                                        "val": "The Adaptable Navigation Systems (ANS) program will provide the U.S. warfighter with the ability to navigate effectively in all environments, including when Global Positioning System (GPS) is unavailable due to hostile action (jamming) or blockage by structures and foliage.  The ANS approach relies on two major technology innovations.  The first is the use of Signals of Opportunity (SoOp) from a variety of ground, air, and space-based sources.  These will be received on the Services' forthcoming software-defined radios and use specially tailored algorithms to determine position.  The second technology innovation allows SoOp-based position information to be combined with inertial and other sensors to enable flexible navigation systems that can be reconfigured in the field to support any platform or environment.  While component technology for positioning, navigation, and timing is advancing rapidly (in the form of Micro Electro-Mechanical System devices, clocks, and new aiding sensors), real-time integration and reconfiguration of these components is not possible given today's navigation filters and centralized processing architectures, which are inherently fragile to change.  Recent advances in mathematics, data abstraction, and network architectures could enable \"plug-and-play\" integration of both existing and future navigation components to allow real-time integration and reconfiguration of navigation systems.  If successful, major improvements in navigation accuracy and system cost could also be realized.  Early transition partners would include all Services, with emphasis on platforms and users that must operate in multiple environments."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "14.497"
                                            },
                                            "Text": {
                                                "val": "-  Developed non-form-fit prototype ANS system.\n-  Demonstrated ANS prototype system in urban canyons and inside buildings.\n-  Conducted field tests and demonstrated the functional ANS prototype in user-selected environments such as forested, jungle and open environments, and for airborne platforms.\n-  Validated performance prediction models from previous phases for use in mission planning tools.\n-  Identified candidate filter, sensor, and architecture designs to enable plug-and-play all environment precision navigation and timing.\n-  Quantified the required performance including accuracy and reconfiguration robustness to enable plug-and-play all environment precision navigation and timing."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "14.471"
                                            },
                                            "Text": {
                                                "val": "-  Evaluate candidate filter, sensor, and architecture design for plug-and-play system.\n-  Conduct tests to compare plug-and-play navigation system performance with existing state-of-the-art.\n-  Develop system specification for platform-specific form factor of ANS reference stations.\n-  Demonstrate SoOp-based ranging and navigation.\n-  Develop and demonstrate through-the-earth communications for navigation (surface-to-subsurface communications).\n-  Test and evaluate first generation 6-degree-of-freedom cold atom-based inertial measurement unit (IMU) in laboratory.\n-  Design second generation cold atom-based IMU to meet platform-specified size, weight and power goals and begin planning for in-flight and\/or at-sea testing."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "16.802"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "16.802"
                                            },
                                            "Text": {
                                                "val": "-  Develop and test candidate filter, sensor, and architecture design for plug-and-play system.\n-  Develop ANS reference stations to user-selected platform-specific form factors.\n-  Demonstrate integration of SoOp-based ranging and navigation into ANS systems.\n-  Test and evaluate ANS systems in sea, air, and land-based platforms in GPS-denied mission scenarios.\n-  Test and evaluate second generation 6-degree-of-freedom cold atom-based IMU in flight and\/or at sea."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Adaptable, Low Cost Sensors"
                                    },
                                    "Description": {
                                        "val": "The objective of the Adaptable, Low Cost Sensor program is to leverage commercial technology and commercial manufacturing techniques to improve the development time and significantly reduce the cost of sensors and sensor systems.  Military sensors are currently developed as unique designs that fully integrate mission specific hardware required for sensing, with all of the other non-mission specific capabilities, including sensors (GPS), processing, memory storage and communications into a single device.  Not only does this approach significantly increase the cost of the device, it makes changing requirements and the upgrading of any specific component extremely difficult.  Nevertheless, significant advances have been made in the capabilities of commercial equipment for almost all of those capabilities, mostly driven by the smart phone industry.  This makes it possible to create a mission-independent, designed-to-cost \"commercial smart core\" that can be combined with an appliqu\u00e9 of mission-specific hardware to provide the overall sensing capability.  Because the core can be upgraded independently of any particular sensor, sensors can make use of the advances and decreasing cost that is inherent in commercial technology.  Because commercial technology can be used in the core, commercial development and manufacturing techniques can also be leveraged, further improving the cost and development time of sensor systems.  In addition, this program will enable effective distributed sensor systems that were previously infeasible due to high cost of individual sensors.  This program will transition to the Services."
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "20.697"
                                            },
                                            "Text": {
                                                "val": "-  Manufacture initial version of commercial smart core.\n-  Identify candidate sensors for ground and airborne demonstrations and quantify the required performance, including adaptability.\n-  Define objectives for distributed sensor systems (ground and UAV) and quantify performance against traditional, non-distributed systems.\n-  Develop a distributed ground sensor system using smart core.\n-  Develop smart core re-usable software and ground mission software.\n-  Define objectives for ground system field test and plan field test activities."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "22.013"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "22.013"
                                            },
                                            "Text": {
                                                "val": "-  Manufacture second version of commercial smart core.\n-  Develop a cooperative sensor systems using smart core.\n-  Refine smart core re-usable software and ground mission software.\n-  Conduct field test of prototype sensor."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Visibuilding"
                                    },
                                    "Description": {
                                        "val": "The Visibuilding program developed technologies and systems for new building surveillance capabilities to detect personnel within buildings, determine building layouts, and locate weapons caches within buildings.  This program developed techniques to inject and recover probing radar waveforms and unravel the complicated multipath in the return signals to enable the mapping and characterization of building interiors.  Radar signals were used to image static structures directly.  Doppler processing of radar signals was also being exploited to find, identify, and perform feature-aided tracking of moving personnel within a building and allow mapping of building pathways and stairways by monitoring traffic through buildings.  Multipath and propagation effects were modeled and iteratively compared with hypotheses of building structures to provide 3-D building maps and large concentrations of metal materials like weapons.  Technologies developed under this program will be made available to the Army and U.S. SOCOM for transition."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "5.345"
                                            },
                                            "Text": {
                                                "val": "-  Completed demonstrations of low-latency, radar-based prototype system and quantified ability to determine building layout and track insurgents within furnished multi-story buildings.\n-  Identified viable alternative sensing modalities for continued development."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "3.700"
                                            },
                                            "Text": {
                                                "val": "-  Transition the radar-based prototype to Army and U.S. SOCOM."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Function Optical Sensor"
                                    },
                                    "Description": {
                                        "val": "The expanded use of passive electro-optic (EO) sensors for detection and tracking (Infrared Search & Track Systems and Forward Looking Infrared Radar Systems) has increased the threat to our airborne systems.  These sensors negate the advantages of our radars and radio frequency (RF)-based countermeasures such as digital radio frequency memory (DRFM).  When used in the presence of DRFM and other RF countermeasures by our adversaries, EO sensors could provide overmatching defensive capabilities.  The Multi-Function Optical Sensing program will provide an alternative approach to detecting, tracking, and performing non-cooperative target identification, as well as providing fire control for fighter class and long-range strike aircraft.  This approach leverages emerging high-sensitivity focal plane array (FPA) and compact, multiband laser systems technology in the near\/mid\/long-wave infrared bands to develop a multi-function optical system.  Technical challenges include the demonstration of inexpensive, multiband, large-format, photon-counting, high-bandwidth receivers and their integration into a multi-optical sensor suite compatible with airborne assets.  The Multi-Function Optical Sensor program will result in an airborne system that can detect, geolocate, and identify targets at standoff ranges.  Technologies from this program will transition into the Services."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "8.500"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "8.500"
                                            },
                                            "Text": {
                                                "val": "-  Initiate development of multiband, high-speed active focal plane arrays. \n-  Develop preliminary system architecture for airborne multi-function optical sensors.\n-  Initiate development of new algorithms and signal processing approaches for effective use of multi-function optical sensing in offense and defensive applications."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Electro-Optical Warfare"
                                    },
                                    "Description": {
                                        "val": "The proliferation of optical communications and sensor systems has created a need for electronic warfare (EW) approaches that can be used in the electro-optical (EO) domain.  Unfortunately, while there is a sophisticated suite of counter RF approaches, there is no such capability against EO signals, which are hard to find; and when found, even harder to suppress.  The EO Warfare program will extend EW into the optical domain by developing the capacity to defeat EO systems including: laser communications systems, EO\/IR sensors, and laser imagers and seekers.  This program will exploit the significant advances that have been made in compact lasers, laser spectrum agility, and microelectronics to develop optical EW systems including an optical digital radio frequency memory (DRFM) equivalent.  Key challenges include detection and processing of optical signals for sensors (photon gating, embedded signal processing) integrated with detector arrays, and adaptive and computational optics that can be applied to finding EO-based communications and active sensors.  The product of the EO Warfare program is to develop new techniques and systems that can defeat laser communications and active optical sensor systems at >50km range.  Improved understanding of countermeasures to active sensors will also improve the robustness of our own developmental and fielded Intelligence, Surveillance and Reconnaissance (ISR) and communications systems.  Technologies from this program will transition to the Services."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "3.550"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "3.550"
                                            },
                                            "Text": {
                                                "val": "-  Identify the capabilities and shortfalls of detector arrays and compact lasers for detecting and suppressing EO threats.\n-  Initiate, based on identified shortfalls, the development of advanced detector arrays and improvements to compact lasers.\n-  Initiate the development of novel signal processing techniques that take advantage of advances in adaptive and computational optics and embedded processing initiatives. \n-  Investigate the use of high-powered EO techniques to saturate or degrade optical receiver performance."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Modal Tunnel Detection"
                                    },
                                    "Description": {
                                        "val": "In today's asymmetric warfare, adversaries' persistent and expanded use of underground tunnels for tactical advantage is largely unchallenged.  Underground and subterranean tunnels are being increasingly employed to hide a variety of tactical and strategic functions, including command and control, missile and artillery protection, lines of communication and staging area for military operations.  Today's tunnel detection systems are based on single mode commercial sensor technology (Ground Penetrating Radar, seismic, resistivity, gravity, cone penetrator, and electromagnetic gradiometer).  Despite significant technical efforts, these approaches still fail to identify tunnels in the presence of variable geology and urban complexity and clutter.  Moreover, there is currently no technical basis for combining these modes into a more powerful detection schema.  The Multi-Modal Tunnel Detection program will overcome these limitations by going back to basics to exploit the underlying physics of a tunnel's response to a variety of energy sources (acoustic, seismic, electromagnetic, chemical, resistivity, conductivity, lidar, multi\/hyperspectral, and gravity\/gravity gradient).  This multi-sensor approach will be used in conjunction with advanced mathematics, new algorithms and processing techniques to develop and demonstrate approaches that optimally combine sensor modalities to characterize tunnels and reject clutter.  Upon completion the Multi-Modal Tunnel Detection program will deny the use of underground facilities that currently thwart our existing ISR systems.  This capability is expected to transition to the U.S. Army, U.S. Marine Corps, and U.S. Special Operations Command upon completion of a system demonstration phase."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "3.550"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "3.550"
                                            },
                                            "Text": {
                                                "val": "-  Begin investigation of the fundamental interactions of various sensor modalities and geological structures indicative of tunnels and underground facilities.\n-  Begin exploration of algorithms to combine sensor information."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Low-Altitude Airborne Sensor System (LAASS)"
                                    },
                                    "Description": {
                                        "val": "The Low-Altitude Airborne Sensor System (LAASS) program developed airborne sensing capabilities to find and characterize underground facilities (UGFs) used to shield and protect strategic and tactical activities.  This includes command and control, weapons storage, manufacture of weapons of mass destruction (WMD), and tunnel networks that breach secure borders and perimeters.  By passively capturing emissions associated with underground facility presence and operations, and doing so using airborne sensors (acoustic, electromagnetic, gravity gradiometry), LAASS significantly increased our ability to seek out underground facilities and map out their vulnerabilities and backbone structure.  LAASS technologies have been made available to Northern Command, Southern Command, Strategic Command, and Defense Threat Reduction Agency for transition."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.065"
                                            },
                                            "Text": {
                                                "val": "-  Identified, through modeling and laboratory tests, the critical development risks for the concept system design, component gravity gradiometry sensor technologies, and supporting subsystems.\n-  Documented expected performance of system concept (sensor, installation, processing, CONOPS).\t\n-  Conducted multi-modal fusion study to validate clutter rejection and tunnel detection improvement."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Rescue Transponder (RT)"
                                    },
                                    "Description": {
                                        "val": "Building upon technologies developed in other sensor programs, the Rescue Transponder (RT) program investigated the use of a unique localization and tracking technology to provide a very low probability of detection (LPD) call for help signal.  The system used a wideband radio frequency signal with low power and extremely low duty cycle.  The program developed a small, rugged transponder that provides a call for help to friendly forces.  The RT system operates over ranges that enable rescue forces or surveillance systems to receive its signals.  It supports accurate localization by rescue forces, and permits transmission of identifying, authenticating, and status information.  The RT technology is transitioning to the Marine Corps."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "1.000"
                                            },
                                            "Text": {
                                                "val": "-  Completed development and delivered miniaturized receivers and extended-life tags to Marine Corps.\n-  Completed transition to Marine Corps."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Sferic-Based Underground Geo-positioning (S-BUG)"
                                    },
                                    "Description": {
                                        "val": "The Lightning Based (Sferic) Underground Geo-positioning (S-BUG) program addressed the challenges presented when navigating and tracking within underground structures, both manmade and natural, by exploiting the abundance and long propagation range of naturally occurring global lightning events.  As conceived, surface receivers at known locations will compare time difference of arrival of very low frequency (VLF) sferic events and employ super-resolution correlation techniques to accurately determine the VLF source locations.  Any subsurface receiver could also detect the sferics, and real time or post-mission correlation with the surface data will enable geo-location of the subsurface receiver.  Exploitation of naturally-occurring, nondeniable signals has the potential to significantly reduce logistical requirements and increase operational standoff by orders of magnitude (1000+ km).  Technologies have been made available to transition to the U.S. SOCOM and the Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "6.543"
                                            },
                                            "Text": {
                                                "val": "-  Completed design of prototype hardware for subsurface receivers and processors and through-the-earth communications.\n-  Built and tested prototype hardware (receiver and processors) for sferic-based geopositioning and navigation.\n-  Demonstrated above ground to below ground geopositioning."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-02"
                    },
                    "ProjectTitle": {
                        "val": "SENSORS AND PROCESSING SYSTEMS"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "109.476"
                        },
                        "CurrentYear": {
                            "val": "85.495"
                        },
                        "BudgetYearOne": {
                            "val": "96.317"
                        },
                        "BudgetYearOneBase": {
                            "val": "96.317"
                        },
                        "BudgetYearOneOCO": {
                            "val": "0.000"
                        },
                        "BudgetYearTwo": {
                            "val": "94.445"
                        },
                        "BudgetYearThree": {
                            "val": "94.971"
                        },
                        "BudgetYearFour": {
                            "val": "93.971"
                        },
                        "BudgetYearFive": {
                            "val": "108.986"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Sensors and Processing Systems project develops and demonstrates the advanced sensor and processing technologies and systems necessary for the intelligence, surveillance, and reconnaissance (ISR) missions.  Future battlefields will continue to be populated with targets that use mobility and concealment as key survival tactics, and high-value targets will range from specific individual insurgents and vehicles to groups of individuals and large platforms such as mobile missile launchers and artillery.  The Sensors and Processing Systems project is primarily driven by four needs: (a) providing day-night ISR capabilities against the entire range of potential targets; (b) countering camouflage, concealment and deception of mobile ground targets; (c) detecting and identifying objects of interest\/targets across wide geographic areas in near-real-time; and (d) enabling reliable identification, precision fire control tracking, timely engagement and accurate battle damage assessment of ground targets.  The Sensors and Processing Systems project develops and demonstrates technologies and system concepts that combine novel approaches to sensing with emerging sensor technologies and advanced sensor and image processing algorithms, software, and hardware to enable comprehensive knowledge of the battlespace and detection, identification, tracking, engagement and battle damage assessment for high-value targets in all weather conditions and combat environments."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Behavioral Learning for Adaptive Electronic Warfare (BLADE)"
                                    },
                                    "Description": {
                                        "val": "The Behavioral Learning for Adaptive Electronic Warfare (BLADE) program will develop the capability to jam adaptive and rapidly evolving radio frequency (RF) threats in tactical environments and at tactically-relevant timescales.  This will change the paradigm for responding to evolving threats from lab-based manual development to an adaptive in-the-field systems approach.  When an unknown or advanced RF threat appears, BLADE networked nodes will dynamically characterize the emitter, synthesize an effective countering technique, and evaluate jamming effectiveness by iteratively probing, learning, and adapting to the threat.  An optimization process will tailor near-real-time responses to specific threats, producing a countermeasure waveform that maximizes jam effectiveness while minimizing the required jamming resources.  Thus BLADE will enable the rapid defeat of new RF threats and provide the warfighter with real-time feedback on jam effectiveness.  The program is planned for transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "14.000"
                                            },
                                            "Text": {
                                                "val": "-  Developed and evaluated techniques for the detection and characterization of known and unknown communications threats using adaptive threshold detection and open-set signal classification.\n-  Created techniques for jam waveform generation via learning and active probing techniques.\n-  Developed approaches for battle damage assessment to determine jam effectiveness through observation of changes in communications threat behavior."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "19.700"
                                            },
                                            "Text": {
                                                "val": "-  Conduct non-real time testing in a laboratory environment demonstrating detection and characterization of known and unknown signals with sufficient fidelity to validate the program concept.\n-  In non-real time, demonstrate the successful optimization of jamming waveforms using  active probing and learning techniques.\n-  Conduct non-real time battle damage assessment performance validation via laboratory testing.\n-  Begin end-to-end system development for real-time open-air breadboard demonstrations.\n-  Develop and evaluate techniques for the detection and characterization of known and unknown radar threats."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "16.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "16.000"
                                            },
                                            "Text": {
                                                "val": "-  Optimize BLADE algorithms for real-time over-the-air operations and port to suitable breadboard computing platforms.\n-  Perform construction, integration and testing of real-time hardware implementation.\n-  Develop Red Team over-the-air testing methodology and perform system evaluations.\n-  Enhance and refine BLADE transition plan in concert with relevant programs of record and Service partners.\n-  Demonstrate initial adaptive radar countermeasure techniques."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Military Imaging and Surveillance Technology (MIST)"
                                    },
                                    "Description": {
                                        "val": "The Military Imaging and Surveillance Technology (MIST) program will develop a fundamentally new optical ISR capability that can provide high-resolution 3-D images to locate and identify a target at much longer ranges than is possible with existing optical systems.  Several prototype optical surveillance and observation systems will be developed that will: (1) demonstrate probabilities of recognition and identification at distances sufficient to allow stand-off engagement; (2) overcome atmospheric turbulence, which now limits the ability of high-resolution optics; and (3) increase target identification confidence to reduce fratricide and\/or collateral damage.  The program will develop and integrate the necessary component technologies including high-energy pulsed lasers, receiver telescopes that have a field of view and depth of field that obviates the need for steering or focusing the optical system, computational imaging algorithms to improve system resolution, and data exploitation and analysis tools. \n\nAdvances in laser systems, digital imagers, and novel image processing algorithms will be leveraged to reduce the overall size, weight and power of imaging systems to allow for soldier portable and UAV platform integration. \n\nMIST will also continue to integrate technologies developed under the Crosswind Sensor System for Snipers (C-WINS) and the Dynamic Image Gunsight Optics (DInGO) efforts.  MIST will develop an optical rifle scope that enables a soldier, with minimal training, to shoot a firearm with marksman accuracy at range while also enhancing the capability for close quarters combat.  The MIST program will transition the developed rifle-scope to the Army, Marines, and Special Operations Forces.  The optical ISR technology will transition to the Air Force and SOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "11.993"
                                            },
                                            "Text": {
                                                "val": "-  Completed design of the DInGO rifle-scope that will allow for retrofit upgrade as well as stand-alone application.\n-  Conducted laboratory demonstration of a high-energy pulsed fiber laser subsystem that is phase-locked to an external reference.\n-  Demonstrated a high-energy pulsed fiber laser with output power that can be scaled well above fundamental limitations of existing fiber laser systems.\n-  Completed the Preliminary Design Review level design for the MIST 3-D short-range imaging system based on advanced computation imaging techniques.\n-  Completed laboratory demonstration of the MIST 3-D short-range imaging system to assess the performance of computational imaging in high-resolution ISR sensors.\n-  Commenced development of a quarter-scale MIST 3-D imaging demonstrator prototype.\n-  Demonstrated the ability to increase the resolution of the MIST imaging technology by coherently phasing multiple independent apertures.\n-  Demonstrated that the MIST short-range receiver design provides a 25x increase in depth-of-focus and field -of-view compared to existing systems.\n-  Completed real-time hardware implementation of advanced image processing algorithms and system integration."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "31.645"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of a high-power pulsed fiber laser system with a size, weight, and power that is suitable for integration on a small or persistent airborne platform.\n-  Complete development of the DInGO rifle-scope prototype that provides a 1-10x image magnification as well as advanced computation algorithms to assist with target tracking, image enhancement, and image stabilization.\n-  Complete field testing of the prototype DInGO scopes in conjunction with the transition partner.\n-  Complete a Critical Design Review level design for the MIST short-range 3-D imaging system.\n-  Complete a brassboard demonstration of MIST short-range imaging designs that incorporates computational imaging and 3-D digital holographic imaging techniques to achieve the short range performance metrics.\n-  Complete development of two quarter-scale MIST 3-D imaging demonstrator prototypes.\n-  Begin integrating the high peak-power pulsed laser technology to increase the operating distance of the MIST 3-D imaging effort.\n-  Begin development of the MIST short-range 3-D imaging prototype for surveillance and identification applications.\n-  Begin to develop designs to extend the MIST operating range for aerial platforms.\n-  Port algorithms from a Colfax processor to a mini processor board that is camera independent.\n-  Begin development of rifle mount crosswind sensor system.\n-  Evaluate rifle mounted crosswind sensor technologies."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "40.955"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "40.955"
                                            },
                                            "Text": {
                                                "val": "-  Transition the quarter-scale MIST designs and prototypes.\n-  Complete development of MIST short-range 3-D imaging prototypes.\n-  Complete a Critical Design Review level design of the MIST 3-D long-range imaging system for operation on aerial platforms.\n-  Demonstrate key technologies to enable operation at increased ranges.\n-  Demonstrate rifle mounted crosswind sensor system. \n-  Transition the rifle mounted crosswind sensor system to the Marine Corps."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multifunction RF"
                                    },
                                    "Description": {
                                        "val": "The Multifunction RF program initially developed a helicopter pilot performance enhancement system for landing in degraded visual environments (DVE) such as dust clouds.  Beyond landing aids in DVE, RF-based sensors can also be used for additional situational awareness, such as near ground obstacle avoidance, air-to-air collision avoidance, targeting\/fire control, as well as many other combat support activities.  Building on advancements made with RF sensors under this program, the program will further seek to eliminate many redundant RF elements of current independently-developed systems for landing in DVEs, terrain avoidance, obstacle avoidance, and targeting\/fire control.  This will reduce the overall weight, power usage, cost, and profusion of exterior antennas on military aircraft, thus enabling greater mission capability with reduced vehicle system integration burden.  Transition is planned to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.500"
                                            },
                                            "Text": {
                                                "val": "-  Began system analysis of extreme high frequency multifunction radar.\n-  Initiated design and development of advanced silicon tiles for electronically scanned antenna."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "15.800"
                                            },
                                            "Text": {
                                                "val": "-  Initiate hardware design and development of multifunction RF system for advanced DVE sensor and lethality functions.\n-  Complete initial demonstration of advanced silicon tile for electronically scanned antenna for multifunction RF sensor.\n-  Define universal synthetic vision interface and demonstrate synthetic vision system in laboratory tests."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "26.862"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "26.862"
                                            },
                                            "Text": {
                                                "val": "-  Complete laboratory testing of advanced DVE sensor suitable for flight testing.\n-  Complete development and laboratory testing of key subsystem technologies for multifunction RF waveforms and arrays.\n-  Flight test synthetic vision system with Government Furnished Equipment sensor on Blackhawk platform."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Advanced Airborne Optical Sensing"
                                    },
                                    "Description": {
                                        "val": "The Advanced Airborne Optical Sensing program is developing electro-optical and infrared sensors and processing technologies for aerial platforms.  Significant challenges have arisen as the result of two warfighting trends.  First, the ever-changing mix of airborne platforms now includes a greater number of smaller UAVs.  Second, the target set is increasingly challenging and now includes vehicles and individual dismounts that operate under foliage and in urban canyons, using camouflage, obscurants, and other means of concealment.  In response to these challenges, the Advanced Airborne Optical Sensing program has developed enhanced optical, electro-optical, photonic and other technologies for airborne optical sensing systems.  Specific examples of these technologies include: embedded image processors tailored to real-time detection, identification, and tracking of military targets; advanced laser radar technologies; hyper-spectral sensing technologies; flash detection and underwater object detection; advanced digital signal processing to support onboard image reconstruction, atmospheric correction, and system calibration; and adaptive optics techniques, such as deformable mirrors and liquid crystal spatial light modulators.  The program has extended these technologies and is making them practical for airborne surveillance systems. Efforts in this program include:\n\n- The Standoff Precision ID in 3-D (SPI 3-D) program developed an affordable sensor package capable of high-resolution 3-D imaging for confirmatory target ID at long ranges, as well as full field of view (FOV) ranging to support precise geolocation of targets.  The program included a series of ground-based and airborne demonstrations of SPI 3-D capabilities including: (1) high range resolution 3-D imaging; (2) full FOV range to pixel determination; (3) multiple frame-to-frame registration of imagery; and (4) GPS-based cueing from search systems.  The program will also produce high speed, ultra-sensitive photo detectors for systems requiring operation at very low photon counts.  This supports long-range sensors that can detect highly obscured targets under canopy\/camouflage as well as very wide-area searches for submerged targets, including sea mines and semi-submerged mobile vessels.\n\n- The HALOE (High Altitude Lidar Operations Experiment) program has demonstrated, in an operational environment, the full capability of a 3-D imaging system.  The HALOE system provides support for current and emerging warfighter needs by delivering high-resolution, wide-area 3-D lidar imagery data in the OCONUS environment.  This system provides the unprecedented capability to collect accurate, high resolution 3-D data over wide areas to support a wide range of high-value applications, including detailed mission planning, vertical obstruction detection, helicopter landing zone analysis, and imagery geolocation.  The pathway to accomplish this goal includes improving the robustness and reliability of the sensor, conducting demonstrations, and training with CONUS flight tests leading to OCONUS operational experimentation in partnership with the Army.\n\nHALOE successfully completed the CONUS flight testing phase and was deployed OCONUS for further testing and system checkout to address current and emerging needs of U.S. forces under the direction of commanders in theater during 2011.  The completed HALOE system will transition to the U.S. Army. \n\n- The Tactical Aircraft to Increase Long Wave Infrared Nighttime Detection (TAILWIND) program developed a system for collecting and processing IR data operating as a framing sensor.  The system accepts long wave infrared and color camera images permitting day\/night reconnaissance for real-time target detection and tracking.  The resulting sensor and processing system will decrease the time required to focus the sensor operator's attention on relevant targets.  The TAILWIND system is planned for transition to the U.S. Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "12.618"
                                            },
                                            "Text": {
                                                "val": "Standoff Precision ID in 3-D (SPI 3-D)\n-  Completed integration of miniaturized components into the demonstration system.\n-  Conducted ground and airborne demonstrations of the metric sensing and 3-D imaging on a manned aircraft, supporting transition to U.S. Air Force.\n-  Designed and implemented target detection, identification, and tracking algorithms in high-performance signal processing hardware architectures.\n-  Developed promising technologies identified for use for air platform to air target identification and location.\n\nHigh Altitude Lidar Operations Experiment (HALOE)\n-  Deployed OCONUS and conducted test demonstrations.\n-  Transitioned HALOE system to the Army in 2011.\n-  Explored possible designs and development of compact configurations of HALOE that could be integrated with military unmanned and manned platforms.\n\nTactical Aircraft to Increase Long Wave Infrared Nighttime Detection (TAILWIND)\n-  Completed final design of infrared and color sensor package."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "7.700"
                                            },
                                            "Text": {
                                                "val": "High Altitude Lidar Operations Experiment (HALOE)\n-  Explore additional applications for the high performance LIDAR components embedded within the HALOE system to optimize size, weight, and power for alternate platforms."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "6.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "6.000"
                                            },
                                            "Text": {
                                                "val": "High Altitude Lidar Operations Experiment (HALOE)\n-  Develop additional applications for the high performance LIDAR components embedded within the HALOE system to optimize size, weight, and power for alternate platforms."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Video-rate Synthetic Aperture Radar (ViSAR)"
                                    },
                                    "Description": {
                                        "val": "Recent conflicts have demonstrated the need for close air support by precision attack platforms such as the AC-130J or the MH-60 class helicopters in support of ground forces.  Under clear conditions, targets are easily-identified and engaged quite effectively, but in degraded environments the atmosphere is not always clear, and inhibits traditional optical sensors.  The AC-130J must fly above cloud decks in order to avoid anti-aircraft fire, and this negates optical targeting sensors.  Similarly, rotary\/wing blades in urban operations generate copious amounts of dust that block circling assets from supplying cover fire for ground forces.  The Video-rate Synthetic Aperture Radar (ViSAR) program will develop a real-time spotlight synthetic aperture radar (SAR) imaging sensor that will provide imagery of a region to allow high-resolution fire direction in conditions where optical sensors do not function.  Technology from this program is planned to transition to AFSOC."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "6.500"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "6.500"
                                            },
                                            "Text": {
                                                "val": "-  Initiate hardware design and development of transmitter and receiver components.\n-  Evaluate RF sensor design concepts that will enable high-resolution targeting information through low altitude clouds.\n-  Assess impacts of various platforms and global weather conditions on targeting performance."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Autonomous Real-time Ground Ubiquitous Surveillance (ARGUS) *"
                                    },
                                    "Description": {
                                        "val": "* Previously called Wide Area Video Surveillance\n\nThe Autonomous Real-time Ground Ubiquitous Surveillance program is developing airborne sensor systems that provide a persistent, real-time, high-resolution, wide-area, day-night video surveillance capability.  The ARGUS Infrared System (ARGUS-IR) uses an advanced infrared (IR) composite focal plane array (CFPA) sensor.  The nighttime persistent capability provided by ARGUS-IR combined with the daytime capability provided by the ARGUS Imaging System (ARGUS-IS) enables 24-hour day\/night surveillance.  ARGUS-IR's wide-area, high-update-rate, high-resolution imaging capability will enable detection and tracking of dismounts as well as vehicles.  ARGUS-IR will utilize the signal\/image processor developed as part of ARGUS-IS, enabling ARGUS-IS and ARGUS-IR to be combined on a common platform.  ARGUS-IR must overcome a number of demanding technical challenges related to the IR Focal Plane Array and size, weight, and power constraints for the IR sensor.  A transition plan is being developed with the U.S. Air Force and U.S. Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "16.000"
                                            },
                                            "Text": {
                                                "val": "-  Completed the initial design of the IR CFPAs.\n-  Completed the initial development and build of the optics for the IR sensor.\n-  Completed initial software and firmware development.\n-  Completed development of the airborne processing system hardware."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "10.650"
                                            },
                                            "Text": {
                                                "val": "-  Transition ARGUS-IS to the Army as part of the Army\/ARGUS-IS\/A-160 (AAA) Quick Reaction Capability.\n-  Integrate the IR sensor into the gimbal.\n-  Integrate the IR sensor and airborne processing system onto a designated platform.\n-  Conduct integration and ground testing on a manned platform.\n-  Conduct IR sensor system and airborne processing system qualification and air worthiness testing.\n-  Conduct initial flight testing on a manned and \/ or unmanned platform.\n-  Transition ARGUS-IR system to the Army and Air Force."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Advanced Electronic Warfare"
                                    },
                                    "Description": {
                                        "val": "The Advanced Electronic Warfare program developed a system that enabled highly precise communications jamming.  This program developed and demonstrated robust, low cost, small size, weight, and power (SWaP) distributed electronic warfare (EW) platforms that allow the warfighter to disrupt and impede an adversary's communication network.  The program used an array of nodes that have synchronized clocks to enable the signal from each node to be aligned so that the carrier and phase jamming are focused on the specific target area and do not affect the non-target area.  Each node contains localization, network, synchronization, and jamming processing and communication in a low-cost, easily deployable package.  Technologies developed under this program have been made available to the Services for transition."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "7.128"
                                            },
                                            "Text": {
                                                "val": "-  Conducted initial field experiments using multiple pole-mounted payloads to validate the ability to synchronize and direct energy to an area of interest and extract measurements of performance.\n-  Conducted advanced experiments with improvements in distributed precision clock synchronization and initial multi-node over the air demonstrations with fixed nodes."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Large Area Coverage Search-while-Track and Engage (LACOSTE)"
                                    },
                                    "Description": {
                                        "val": "The Large Area Coverage Search-while-Track and Engage (LACOSTE) program explored persistent, tactical-grade ground-moving target indicator (GMTI) capability in dense urban areas.  Wide-area continuous tracking of moving vehicles requires very small coverage gaps, small resolution cells, and target separation and identification features.  The ideal sensor has the area coverage rates of GMTI radar and the resolution\/identification capabilities of an electro-optical infrared system.  The LACOSTE program provided wide area surveillance, simultaneous tracking, and target engagement with electro-optical and infrared sensors for tactical GMTI operations.  The program developed a  sensor with a very wide field of regard, and a wide instantaneous field of view (FOV) that is rapidly scanned in a search-while-track mode, tracking up to thousands of targets in an urban area.  Additionally, the LACOSTE sensor provides next-generation precision tracking to enable engagement on a large number of targets in dense urban areas within that same field of regard with minimal penalty on the search-mode area coverage rate.  The program also developed a rapid \"zoom\" capability for target identification that enables feature-aided tracking through dense target environments, plus sufficient target identification for separating like-targets when back-tracking a particular target via the historical track data.  The LACOSTE technology was transitioned to the U.S. Air Force and the U.S. Army at the conclusion of the program."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.110"
                                            },
                                            "Text": {
                                                "val": "-  Conducted demonstration of sensitivity, resolution, and tracking."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "NetTrack"
                                    },
                                    "Description": {
                                        "val": "The NetTrack Program developed feature-aided tracking technologies to enable airborne surveillance radars to maintain track on moving high value targets (HVTs) in traffic and cluttered environments.  Ground moving target indicator (GMTI) radars provide excellent potential for tracking HVTs because they operate in all weather and at long ranges.  However, maintaining target tracks is very challenging because obscuration and close target spacing make it difficult to associate radar kinematic measurements over time.  To address this challenge, NetTrack developed feature aided tracking technology that automatically collects and exploits target high range resolution (HRR) radar measurements.  Specific NetTrack technologies include signal processing to generate HRR measurements from raw radar returns, feature extraction and matching to exploit HRR measurements, multiple hypothesis tracking to associate measurements to tracks and estimate target location and velocity, and sensor resource management to automatically select optimum radar mode parameters and timing sequences.  A Memorandum of Agreement (MOA) has been established for transition of NetTrack to the Navy Advanced Airborne Sensor which is a follow-on to the Navy Littoral Surveillance Radar System."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.000"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrated feature aided tracking in traffic and cluttered environments.\n-  Collected maritime data and investigated extensions of the NetTrack capabilities to the maritime environment.\n-  Planned and initiated an extension to facilitate an Operational Utility Assessment (OUA) with the Navy.\n-  Developed plans to conduct and carry out several Integration & Test (I&T) flights prior to the OUA demonstration."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Precision Inertial Navigation Systems High Dynamic Range Atom Sensors and Systems (PINS HiDRA)"
                                    },
                                    "Description": {
                                        "val": "Precision Inertial Navigation Systems High Dynamic Range Atom Sensors and Systems (PINS HiDRA) developed an integrated cold atom-based inertial measurement unit (IMU) suitable for use on a wide range of military platforms.  The program built on the work of the Precision Inertial Navigation Systems (PINS) program to dramatically increase the dynamic range of the sensors, thereby enabling operation on aircraft and missiles.  Extensive system integration and miniaturization reduced system size, weight, and power, while increasing navigation performance as measured against currently fielded aircraft inertial navigation systems.  Technologies from the PINS HiDRA program have transitioned to the Adaptable Navigation Systems program budgeted at PE 0603767E, SEN-01."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.135"
                                            },
                                            "Text": {
                                                "val": "-  Designed system microcontroller and compact laser and optomechanics frame.\n-  Developed computer models for atom sensor operation under high dynamic input and predicted navigation performance under relevant sensor configuration.\n-  Validated sub-system technology selections and incorporated into full six degree-of-freedom inertial sensor design."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Wide Area Surveillance - Overseas Contingency Operations (OCO)"
                                    },
                                    "Description": {
                                        "val": "The Wide Area Surveillance program operationalized wide area surveillance technologies for accelerated transition to DoD programs and systems.  Technologies of specific interest included sensor models with sufficient accuracy to support tactical targeting; integrated ground-airborne processing; and advanced processing, exploitation, and dissemination for the ARGUS-IS and ARGUS-IR next generation wide area electro-optical (EO) and IR sensors.  Additional capabilities for long duration missions, such as those needed by advanced airships, were also developed.  The efforts are transitioning to the Army AAA QRC, Air Force Gorgon Stare QRC, Air Force Blue Devil Block 2 QRC, Air Force Broad Area Surveillance Sensors (BASS) Program, and the Army Long Endurance Multi-Intelligence Vehicle (LEMV) Program."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "38.992"
                                            },
                                            "Text": {
                                                "val": "-  Accelerated the development of the ARGUS-IS Gen 2 processor.\n-  Validated the ARGUS-IS sensor model.\n-  Enhanced ARGUS-IS tactical wide area retrospective persistence for forensics analysis and initiated integration of ARGUS-IS ground processing.\n-  Implemented long duration mission enhancements for ARGUS-IS\/ARGUS-IR\/AAA.\n-  Accelerated ARGUS-IR development efforts."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-03"
                    },
                    "ProjectTitle": {
                        "val": "EXPLOITATION SYSTEMS"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "62.995"
                        },
                        "CurrentYear": {
                            "val": "83.999"
                        },
                        "BudgetYearOne": {
                            "val": "65.619"
                        },
                        "BudgetYearOneBase": {
                            "val": "65.619"
                        },
                        "BudgetYearOneOCO": {
                            "val": "0.000"
                        },
                        "BudgetYearTwo": {
                            "val": "55.199"
                        },
                        "BudgetYearThree": {
                            "val": "57.013"
                        },
                        "BudgetYearFour": {
                            "val": "57.013"
                        },
                        "BudgetYearFive": {
                            "val": "60.013"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis.  Efforts will focus on difficult ISR environments, for example (a) urban environments with extensive building obscuration, large volumes of civilian traffic, and feature-rich terrain, (b) mountain environments with highly variable terrain elevation, complex local and regional threat networks, and predominantly dismounted adversaries, (c) jungle environments with targets under heavy canopy, animals, and other sources of clutter masking human activity, and (d) maritime and littoral environments where threats now include terrorists, pirates, smugglers, drug traffickers, and other non-traditional adversaries.  The resulting technology will enable operators to more effectively use ISR data in the execution of wide area search, border and road monitoring, high value target tracking, overwatch, and other missions."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Insight"
                                    },
                                    "Description": {
                                        "val": "Insight is developing the next generation multi-intelligence (multi-INT) exploitation and resource management system.  Insight provides new exploitation capabilities through an integrated, standards-based system that is designed for mission flexibility and cross-theater applicability.  Insight will enable detection of threat networks and irregular warfare operations through combination and analysis of information from imaging and non-imaging sensors and other sources.  The technical approach emphasizes model-based correlation, adversary behavior modeling, threat network analysis tools, resource management tools, a unified data management and processing environment, novel exploitation algorithms and analysis methodologies, and tools to integrate human and machine processing, including visualization, hypothesis manipulation, on-line learning, and distributed social intelligence.  Insight development activities leverage both virtual and physical test bed environments.  The virtual test bed enables evaluation of alternative sensor mixes and algorithms under extended operating conditions.  The physical test bed enables live testing, under realistic operational conditions, using current and next generation sensing and processing systems.  Insight technology development is being coordinated with the following potential transition sponsors: Army Program Executive Office-Intelligence, Electronic Warfare & Sensors, Distributed Common Ground System - Army, Army Intelligence and Security Command, Air Force - Distributed Common Ground Station, and the National Geospatial-Intelligence Agency.  Insight provides a unified architecture for plug-and-play ISR with extensibility to all Services and Unified Combatant Commands, initially USCENTCOM, USSOCOM, and USPACOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "37.195"
                                            },
                                            "Text": {
                                                "val": "-  Designed and developed the Insight system baseline architecture to support open, modular, software and hardware components; successfully integrated individual components within the baseline architecture.\n-  Designed and developed architectures and interfaces for the virtual test bed, integrating real-world collected data with simulated sensor data, and simulated threats and terrain features.\n-  Designed and developed multi-source exploitation tools for modeling and detection, element discovery and labeling, and multi-INT fusion.\n-  Designed and developed collection and resource management tools to enable dynamic tasking and cross-cueing capabilities.\n-  Designed and developed an analyst-centered, human-machine interface, enabling rich entity representation, efficient information availability, and meaningfully integrated visual perspectives.\n-  Designed and developed the architectures and interfaces for the physical test bed, enabling baseline integrated system capability assessment.\n-  Developed functional and operational use cases to assess baseline integrated system capabilities.\n-  Developed component and system-level measures of performance and effectiveness, e.g., detection and identification, tracking, location accuracy, timeliness of reporting, network detection, anomaly detection, etc.\n-  Performed component and system-level assessments on relevant datasets.\n-  Successfully executed a component integration demonstration to evaluate system readiness for the first field test."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "50.205"
                                            },
                                            "Text": {
                                                "val": "-  Baseline multi-source exploitation, collection and resource management, and human-machine interface techniques against user-validated operational use cases, scenarios, and concepts of operation (CONOPs).\n-  Establish a virtual test bed for baseline testing of system scalability and fidelity, and analysis of alternative CONOPs.\n-  Populate developmental database with additional operationally diverse, real-world collected data to support rapid prototyping of innovative exploitation, resource management, and analytical tools.\n-  Evaluate multi-INT sensor exploitation and control techniques in the virtual test bed.\n-  Conduct a series of increasingly complex system integration demonstrations to validate architectural design.\n-  Perform a limited field test at the physical test bed with participation by operational users and stakeholders to demonstrate unique system functionality, component interoperability, data flow, usability, and operational impact."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "45.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "45.000"
                                            },
                                            "Text": {
                                                "val": "-  Conduct a system integration demonstration of functionality and performance.\n-  Perform comprehensive field tests with user and stakeholder communities to validate system operational utility highlighting collection and resource management, and exploitation of data from physical sensors, human sources, and contextual databases.\n-  Demonstrate capabilities including multi-source correlation of vast scale across all information sources; dynamic sensor tasking, cross cueing and handoff; hypothesis management of uncertain data; and inference management to prioritize and explain abnormal behaviors.\n-  Integrate the Insight system with live pre-deployment training exercises in coordination with transition partners.\n-  Spin off Insight technologies to fill key capability gaps for existing programs of record.\n-  Conduct virtual test bed exercises to demonstrate exploitation, resource management, visualization, and simulation capabilities.\n-  Conduct a virtual environment challenge to leverage novel approaches to intelligence collection, exploitation, and fusion."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Wide Area Network Detection (WAND)"
                                    },
                                    "Description": {
                                        "val": "The Wide Area Network Detection (WAND) program is developing methods to detect, characterize, and identify threat networks from imaging and other sensors, including national, theater, and organic sensors.  Critical performance metrics are timeliness, accuracy, error rates, and interpretation workload.  The program addresses the challenges of network\/target identification, acquisition, tracking, and denial in difficult environments.  The technologies will apply advanced signal processing, sensor fusion, and platform control to leverage advances in sensor capabilities.  Transition is planned to the Air Force, Army, and SOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "10.000"
                                            },
                                            "Text": {
                                                "val": "-  Completed baseline end-to-end system design.\n-  Expanded modeling and simulation environment to include integrated dismount, vehicle, and communication activities in realistic urban scenarios. \n-  Established informal agreement with SOCOM for use of their assets in flight tests."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "20.874"
                                            },
                                            "Text": {
                                                "val": "-  Conduct live-fly data collection to obtain time-coincident wide-area motion imagery (WAMI) and RF detection data.\n-  Complete fabrication of back end processor and demonstrate capability to create accurate WAMI tracks in real time.\n-  Demonstrate improvement in RF geolocation accuracy and transition enhanced RF sensor capability to SOCOM.\n-  Deliver prototype multi-entity geospatial activity correlator to U.S. Army G-2 Army-A160-ARGUS (AAA) Program. \n-  Integrate and demonstrate techniques on Insight testbed."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "10.619"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "10.619"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate live processing of time-coincident WAMI and RF detection data at CONUS test site.\n-  Demonstrate integrated detection of sites, movements, and communications events associated with threat network activity.\n-  Deliver upgraded multi-entity geospatial activity correlator to U.S. Army G-2 Army-A160-ARGUS (AAA) Program."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Worldwide Intelligence Surveillance and Reconnaissance (WISR)"
                                    },
                                    "Description": {
                                        "val": "The Worldwide Intelligence Surveillance and Reconnaissance (WISR) system will provide ISR capability in denied areas.  The U.S. military has limited capability or permission to obtain airborne ISR observations of many critical problem areas.  Overhead observations are limited by sensor resolution, collection timeline and platform geometry.  However, millions of people worldwide have been recording and posting videos of events and areas of interest for national security.  The number of videos available on public networks is rapidly increasing.  WISR will use the ground-level video and still images to reconstruct 3-D and 4-D timelines of events and will use these reconstructions to code descriptions of dynamic content, rather than focusing on the identification and movement of individual objects and humans in the scene.  WISR constructs will be suitable for describing and differentiating patterns-of-life to reflect local and societal changes.  The program will use this data in support of three missions: intelligence preparation for expeditionary forces entering a new area of operation, reconstruction of significant events worldwide, and battle damage assessment.  These techniques will transition to operational commands and the intelligence community."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "10.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "10.000"
                                            },
                                            "Text": {
                                                "val": "-  Develop and implement techniques for automatically locating and extracting relevant videos and images in a particular area.\n-  Create image understanding techniques to place videos in geographic and chronological context, perform 4-D reconstruction of events, and code the reconstructions based on the dynamic macro-level content of the reconstructions.\n-  Apply image understanding techniques to interpret those reconstructions and videos that meet operator-specified criteria for significant intelligence content."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Sensor Exploitation"
                                    },
                                    "Description": {
                                        "val": "The Multi-Sensor Exploitation program provides multi-sensor exploitation capabilities enabling missions such as overwatch, border surveillance, high value target tracking, and threat network detection using mixes of imaging, radar, signals, human intelligence, and other sources.  The program integrates novel cyber-human-physical sensing and man-machine processing to better take advantage of the strengths of each.  New processing techniques for hyperspectral imaging sensors will enable long duration tracking of vehicles and dismounts.  Scalable stochastic modeling and inference techniques will yield improved situation awareness and assessment for wide-area electro-optical\/IR motion imaging, radar, and multi-sensor exploitation applications in settings where large numbers of interacting entities engaged in complex activities are observed over long periods of time.  Techniques intended for use in riverine and maritime environments, where extremist and criminal groups threaten political stability, trade routes, and free commerce, will map navigable tributary systems, detect and identify threats, and monitor their activity.  Potential transition partners include USAFRICOM, USSOUTHCOM, USSOCOM and intelligence agencies."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "6.900"
                                            },
                                            "Text": {
                                                "val": "-  Evaluated and optimized techniques and software for tracking targets in dense target environments. \n-  Performed preliminary data collects to establish the viability of novel hyperspectral processing and detection techniques. \n-  Collaborated with several potential transition partners to develop operational concepts utilizing the hyperspectral capability. \n-  Hyperspectral experiments successfully demonstrated proof of concept capability.\n-  Tested and refined previously developed detection algorithms to extract thermal spectral signatures of chemical solids and vehicle paints."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "7.720"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate flow-based tracker improvements using instrumented data and in-theater data. \n-  Develop techniques for dealing with riverine and maritime challenges such as turbidity, multi-path reflection, sea clutter, and high clutter density. \n-  Transition the atmospheric downwelling correction algorithms and the sub-pixel detection algorithms into NGA's operational exploitation configuration."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Foliage Penetrating Radar Planning and Exploitation"
                                    },
                                    "Description": {
                                        "val": "The Foliage Penetrating Radar Planning and Exploitation program will complete final FORESTER foliage penetrating radar demonstrations and provide further exploitation capabilities to find dismounted targets in densely forested terrain.  Current foliage penetrating radar systems provide an important capability for detecting dismount targets under foliage, but the systems also detect animals, moving water, blowing trees, and other scene clutter moving under or in the foliage that makes situation assessment, manpower and radar resource intensive.  Further, Doppler signature data that may enable improved automated discrimination of dismount targets from other detections is not currently exploited.  Finally, no planning tools are available for optimizing and dynamically replanning collection assets to improve imaging geometries and detectability.  This program will provide capabilities to address these issues by exploiting Doppler signature data, automating temporal processing approaches currently used, and automating terrain, weather, and on-line exploitation data to enable planning and dynamic replanning.  The result will be significantly improved capability for finding and localizing targets under foliage.  The program will transition to USSOUTHCOM and USSOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "7.500"
                                            },
                                            "Text": {
                                                "val": "-  Formulated, evaluated, and optimized algorithms for mitigating detections in radar systems due to non-living objects in motion and for mitigating confusion between humans and animals.\n-  Formulated, evaluated, and optimized multiple algorithms for assessment of group-state activity level sufficient to assist an operator in assessment of the group's intent."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "5.200"
                                            },
                                            "Text": {
                                                "val": "-  Refine algorithms for performing Doppler discrimination and assessing group state and activity.\n-  Optimize and implement algorithms for the FORESTER processing architecture.\n-  Develop pre-mission planning module to optimize flight path for maximum observeability of target named areas of interest.\n-  Transition system into operational exploitation cells."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Persistent Operations Surface Surveillance and Engagement (POSSE)"
                                    },
                                    "Description": {
                                        "val": "The Persistent Operations Surface Surveillance and Engagement (POSSE) program developed the capability to integrate sensor input from multiple modalities to find indications of insurgent activities.  Combined with dynamically updated information from soldiers on the ground, POSSE has enabled near-real-time generation of the evidence necessary for further investigation or interdiction.  POSSE experiments were conducted at the National Training Center (NTC) with realistic role players emulating typical residential, commercial, and light industrial activity.  Within this environment, insurgent activity was simulated by qualified experts using the latest and most complete intelligence available.  Measurements included precision collections of insurgent activities, as well as the realistic surrounding background clutter of typical civilian activity.  Results informed future experiments, led to specifications for future sensor design, and provided insights into how to integrate other narrow and wide area sensors into an integrated approach to countering insurgencies.  Transition is in process with the U.S. Army Intelligence and Security Command."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "1.400"
                                            },
                                            "Text": {
                                                "val": "-  Refined sensors specific to close-in insurgent activity detection.\n-  Demonstrated new insurgent activity detection techniques in field exercises at the National Training Center."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-CLS"
                    },
                    "ProjectTitle": {
                        "val": "CLASSIFIED"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "55.859"
                        },
                        "CurrentYear": {
                            "val": "63.440"
                        },
                        "BudgetYearOne": {
                            "val": "83.087"
                        },
                        "BudgetYearOneBase": {
                            "val": "83.087"
                        },
                        "BudgetYearOneOCO": {
                            "val": "0.000"
                        },
                        "BudgetYearTwo": {
                            "val": "76.597"
                        },
                        "BudgetYearThree": {
                            "val": "76.373"
                        },
                        "BudgetYearFour": {
                            "val": "76.532"
                        },
                        "BudgetYearFive": {
                            "val": "78.989"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds classified DARPA programs that are reported in accordance with Title 10, United States Code, Section 119(a)(1) in the Special Access Program Annual Report to Congress."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Classified DARPA Program"
                                    },
                                    "Description": {
                                        "val": "This project funds Classified DARPA Programs.  Details of this submission are classified."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "55.859"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "63.440"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "83.087"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "83.087"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Details will be provided under separate cover."
                        }
                    }
                }
            ]
        }
    }
}