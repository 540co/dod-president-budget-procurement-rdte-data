{
    "id": "ba65789a21c67e24344b9ea89720255358d3f0c5",
    "meta": {
        "filename": "dod-2015_RDTE_2015_DARPA_RDTE_JustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2015.zzz_unzipped_RDTE_JustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2015.xml",
        "budget_year": "2015",
        "budget_cycle": "PB",
        "submission_date": "2014-03",
        "service_agency_name": "Defense Advanced Research Projects Agency",
        "appropriation_code": "0400",
        "appropriation_name": "Research, Development, Test & Evaluation, Defense-Wide"
    },
    "record": {
        "@monetaryUnit": "Millions",
        "ProgramElementNumber": {
            "val": "0603767E"
        },
        "ProgramElementTitle": {
            "val": "SENSOR TECHNOLOGY"
        },
        "R1LineNumber": {
            "val": "63"
        },
        "BudgetYear": {
            "val": "2015"
        },
        "BudgetCycle": {
            "val": "PB"
        },
        "SubmissionDate": {
            "val": "2014-03"
        },
        "ServiceAgencyName": {
            "val": "Defense Advanced Research Projects Agency"
        },
        "AppropriationCode": {
            "val": "0400"
        },
        "AppropriationName": {
            "val": "Research, Development, Test & Evaluation, Defense-Wide"
        },
        "BudgetActivityNumber": {
            "val": "3"
        },
        "BudgetActivityTitle": {
            "val": "Advanced Technology Development (ATD)"
        },
        "ProgramElementFunding": {
            "PriorYear": {
                "val": "272.095"
            },
            "CurrentYear": {
                "val": "276.364"
            },
            "BudgetYearOne": {
                "val": "312.821"
            },
            "BudgetYearOneBase": {
                "val": "312.821"
            },
            "BudgetYearTwo": {
                "val": "279.927"
            },
            "BudgetYearThree": {
                "val": "280.978"
            },
            "BudgetYearFour": {
                "val": "300.409"
            },
            "BudgetYearFive": {
                "val": "309.318"
            }
        },
        "ProgramElementMissionDescription": {
            "val": "The Sensor Technology program element is budgeted in the Advanced Technology Development Budget Activity because it funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability and battle damage assessment.  \n\nThe Surveillance and Countermeasures Technology project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing and low-cost microelectronics to develop advanced surveillance and targeting systems.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with tactical information needed to succeed in future wars.  Additionally, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats.  \n\nThe Sensors and Processing Systems project develops and demonstrates the advanced sensor processing technologies and systems necessary for the intelligence surveillance and reconnaissance (ISR) mission.  The project is primarily driven by four needs:  1) providing day-night ISR capabilities against the entire range of potential targets; 2) countering camouflage, concealment and deception of mobile ground targets; 3) detecting and identifying objects of interest\/targets across wide geographic areas in near real-time; and 4) enabling reliable identification, precision fire control, tracking, timely engagement and accurate battle damage assessment of ground targets.\n\nThe Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis."
        },
        "ChangeSummary": {
            "PreviousPresidentBudget": {
                "PriorYear": {
                    "val": "299.438"
                },
                "CurrentYear": {
                    "val": "286.364"
                },
                "BudgetYearOne": {
                    "val": "276.749"
                },
                "BudgetYearOneBase": {
                    "val": "276.749"
                }
            },
            "CurrentPresidentBudget": {
                "PriorYear": {
                    "val": "272.095"
                },
                "CurrentYear": {
                    "val": "276.364"
                },
                "BudgetYearOne": {
                    "val": "312.821"
                },
                "BudgetYearOneBase": {
                    "val": "312.821"
                }
            },
            "TotalAdjustments": {
                "PriorYear": {
                    "val": "-27.343"
                },
                "CurrentYear": {
                    "val": "-10.000"
                },
                "BudgetYearOne": {
                    "val": "36.072"
                },
                "BudgetYearOneBase": {
                    "val": "36.072"
                }
            },
            "AdjustmentDetails": {
                "CongressionalGeneralReductions": {
                    "PriorYear": {
                        "val": "-0.389"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedReductions": {
                    "PriorYear": {
                        "val": "-27.449"
                    },
                    "CurrentYear": {
                        "val": "-10.000"
                    }
                },
                "CongressionalRescissions": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalAdds": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedTransfers": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "Reprogrammings": {
                    "PriorYear": {
                        "val": "8.146"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "SBIRSTTRTransfer": {
                    "PriorYear": {
                        "val": "-7.651"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "OtherAdjustmentDetailList": {
                    "OtherAdjustmentDetail": [
                        {
                            "Title": {
                                "val": "TotalOtherAdjustments"
                            },
                            "Funding": {
                                "BudgetYearOne": {
                                    "val": "36.072"
                                },
                                "BudgetYearOneBase": {
                                    "val": "36.072"
                                }
                            }
                        }
                    ]
                }
            },
            "SummaryExplanation": {
                "val": "FY 2013:  Decrease reflects Congressional reductions for Sections 3001 & 3004 and directed reductions, sequestration adjustments, and the SBIR\/STTR transfer offset by reprogrammings.\nFY 2014:  Decrease reflects a reduction to eliminate program growth. \nFY 2015:  Increase reflects new efforts in Software-Defined Intelligence, Surveillance, and Reconnaissance (ISR), Battlefield Evidence and an increase in classified programs."
            }
        },
        "ProjectList": {
            "Project": [
                {
                    "ProjectNumber": {
                        "val": "SEN-01"
                    },
                    "ProjectTitle": {
                        "val": "SURVEILLANCE AND COUNTERMEASURES TECHNOLOGY"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "52.368"
                        },
                        "CurrentYear": {
                            "val": "53.329"
                        },
                        "BudgetYearOne": {
                            "val": "55.743"
                        },
                        "BudgetYearOneBase": {
                            "val": "55.743"
                        },
                        "BudgetYearTwo": {
                            "val": "55.412"
                        },
                        "BudgetYearThree": {
                            "val": "55.904"
                        },
                        "BudgetYearFour": {
                            "val": "72.557"
                        },
                        "BudgetYearFive": {
                            "val": "80.404"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability, and battle damage assessment.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with the tactical information needed to succeed in future wars.  This operational surveillance capability must continue to perform during enemy efforts to deny and deceive the sensor systems, and operate, at times, in a clandestine manner.  This project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing, and low-cost microelectronics to develop advanced surveillance and targeting systems.  In addition, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Adaptable Navigation Systems (ANS)"
                                    },
                                    "Description": {
                                        "val": "The Adaptable Navigation Systems (ANS) program will provide the U.S. warfighter with the ability to effectively navigate all environments including when Global Positioning System (GPS) is unavailable due to hostile action (jamming) or blockage by structures, foliage, or other environmental obstacles.  The ANS approach relies on three major technology innovations.  The first is development of a new type of inertial measurement unit (IMU) that requires fewer GPS position fixes. Using cold atom technology, this IMU exceeds the performance of strategic-grade IMUs, with comparable size, weight, and power (SWaP).  The second innovation uses Signals of Opportunity (SoOp) from a variety of ground-, air-, and space-based sources, as well as natural SoOps to reduce dependency on GPS position fixes.  These will be received on the Services' forthcoming software-defined radios and will use specially tailored algorithms to determine position.  The third technology innovation allows SoOp-based position information to be combined with inertial and other sensors to enable flexible navigation systems that can be reconfigured in the field to support any platform or environment.  This capability will enhance new advanced component technology for positioning, navigation, and timing (PNT) emerging from other programs in the form of Micro Electro-Mechanical System devices, clocks, and new aiding sensors.  Recent advances in mathematics, data abstraction, and network architectures will build upon these capabilities by enabling \"plug-and-play\" integration of both existing and future navigation components and processing to allow real-time reconfiguration of navigation systems.  If successful, major improvements in navigation accuracy and system cost could also be realized.  Early transition partners would include all Services, with emphasis on platforms and users that must operate in multiple environments, such as Naval forces."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "14.802"
                                            },
                                            "Text": {
                                                "val": "-  Developed and tested candidate filter, sensor, and architecture design for plug-and-play system.\n-  Commenced developing ANS reference stations to user-selected, platform-specific form factors.\n-  Demonstrated integration of SoOp-based ranging and navigation into ANS systems.\n-  Tested and evaluated ANS systems for sea-, air-, and land-based platforms in GPS-denied mission scenarios.\n-  Began designing second-generation 6-degree-of-freedom cold atom IMU."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "15.991"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of candidate filter, sensor, and architecture design for plug-and-play system.\n-  Test and evaluate first-generation 6-degree-of-freedom cold atom-based IMU.\n-  Demonstrate flexible, real-time operation of ANS systems on sea-, air-, and land-based platforms using relevant sensor suites.\n-  Transition novel navigation measurement technologies, via new sensors, algorithms, or measurement enhancements, into ANS demonstration systems.\n-  Evaluate options for size, weight, power, and cost (SWaP-C)-constrained reference stations that enable full SoOp-based navigation.\n-  Complete second-generation 6-degree-of-freedom cold atom IMU and design cold atom-based clock that has the same form\/fit\/function of existing Cesium-based clocks.\n-  Evaluate candidate approaches for a wireless time transfer and positioning system that provides GPS-level performance globally with minimal infrastructure, and a compact, jam-proof PNT sensor that provides better than GPS-level performance."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "15.982"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "15.982"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate inertial navigation performance of a second-generation cold atom-based IMU on a submarine platform.\n-  Demonstrate the navigation performance, independent of GPS, of the integrated ANS system, comprised of various sensors, including IMUs and SoOp receivers, and a sensor fusion processor, on multiple sea-, air-, and land-based platforms."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Adaptable, Low Cost Sensors"
                                    },
                                    "Description": {
                                        "val": "The objective of the Adaptable, Low Cost Sensors program is to leverage commercial technology and manufacturing techniques to improve the development time and significantly reduce the cost of sensors and sensor systems.  Currently, military sensors are designed and developed with unique, mission-specific hardware and software capability requirements into a single, fully integrated device.  This approach significantly increases both the cost and difficulty of meeting continuously changing requirements and upgrades.  Commercial processes, such as those used in the smart phone industry, create reference designs for common system functions and features to accelerate system development time.  This makes change to requirements and completing upgrades far simpler.  Adopting these commercial processes enables a mission-independent, designed-to-cost \"commercial smart core\" that can be combined with an appliqu\u00e9 of mission-specific hardware to provide low cost, independently upgradable, and previously infeasible sensor system distribution capabilities.  The Smart Munitions effort plans to use ADAPT's sensing, processing, communications, and location capabilities to provide positive identification and man-in-the-loop control of distributed, unattended ground sensor systems.  It also seeks to develop a reference design to demonstrate capability and develop tactics for unattended sensors.  This program will transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "19.116"
                                            },
                                            "Text": {
                                                "val": "-  Manufactured second version of commercial smart core.\n-  Developed mobile and airborne development kits using the core hardware and software technology.\n-  Refined smart core re-usable software and ground mission software communications, networking, distributed processing, location, and orientation.\n-  Developed and demonstrated Smart Munitions reference design using a ground sensor packaging of the core technology.\n-  Developed image, video detection, tracking, and display utilities to provide positive target identification in support of the Smart Munitions effort."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "11.338"
                                            },
                                            "Text": {
                                                "val": "-  Develop additional reference designs, including Quad-rotor UAV, Fixed Wing UAV, Unmanned Undersea Vessel (UUV), and Software-Defined Radio.\n-  Configure hardware for heterogeneous distributed sensor mission.\n-  Field test Smart Munitions with multiple sensor modalities."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "6.904"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "6.904"
                                            },
                                            "Text": {
                                                "val": "-  Field test and demonstrate mobile coordinated device operation using ADAPT reference designs (Smart Munitions and UAVs)."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Function Optical Sensing"
                                    },
                                    "Description": {
                                        "val": "The proliferation of radio frequency (RF)-based countermeasures, such as digital radio frequency memory (DRFM), has presented challenges to the effectiveness of data sensors.  The Multi-Function Optical Sensing (MOS) program will enable an alternative approach to detecting, tracking, and performing non-cooperative target identification, as well as providing fire control for fighter class and long-range strike aircraft.  This program leverages emerging high-sensitivity focal plane array (FPA) and compact, multiband laser systems technology in the near\/mid\/long-wave infrared bands to enable the development of a multi-function optical system.  Technical challenges include the demonstration of inexpensive, multiband, large-format, photon-counting, high-bandwidth receivers and their integration into a multi-optical sensor suite compatible with airborne assets.  The Multi-Function Optical Sensor program seeks to advance the state of the art of components and technology to support an all-optical airborne system that can detect, geolocate, and identify targets at standoff ranges.  Technologies from this program will transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "18.450"
                                            },
                                            "Text": {
                                                "val": "-  Initiated development of multiband, high-speed active focal plane arrays.\n-  Initiated development of variable-waveform, high power lasers that demonstrate high wall plug efficiency.\n-  Developed preliminary system architectures for airborne multi-function optical sensors.\n-  Simulated sensor measurements of targets at relevant ranges including the effects of turbulence and atmospheric scattering.\n-  Initiated development of new algorithms and signal processing approaches for effective use of multi-function optical sensing measurements for target tracking and identification.\n-  Investigated concept of operations (CONOPS) for the deployment of a multi-function optical sensor.\n-  Conducted reduced range target measurements to validate simulations."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "26.000"
                                            },
                                            "Text": {
                                                "val": "-  Complete design of prototype sensor through critical design review.\n-  Initiate development of a first-generation prototype sensor.\n-  Incorporate results of CONOPS and algorithm performance on simulated data to refine objective system performance requirements.\n-  Initiate investigation of communications protocols for the multi-optical sensor to interact with other systems and platforms.\n-  Continue development of sensor data-processing algorithms to improve target tracking and identification.\n-  Initiate advanced system signal-processing methodologies for real-time performance and integration into the second-generation sensor system.\n-  Investigate alternative approaches for an active cueing system."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "22.857"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "22.857"
                                            },
                                            "Text": {
                                                "val": "-  Complete the development of the prototype system.\n-  Perform demonstrations with the prototype system in the appropriate environment.\n-  Incorporate advanced data-processing and target tracking algorithms into the sensor processing chain.\n-  Initiate the development of a second-generation prototype sensor, which will demonstrate the full capability out to operational ranges.\n-  Initiate packaging activity for the incorporation of the developed active focal plane arrays and variable-waveform lasers into the second-generation architecture.\n-  Develop a hardware traceability strategy for the second-generation prototype sensor, which will be part of a roadmap for the development of a fully operational system."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Software-Defined ISR"
                                    },
                                    "Description": {
                                        "val": "Currently, radars, electronic warfare (EW) systems, and Electronic Support Measures (ESM) systems consist of custom software and hardware.  Developing new modes for these systems is costly and time consuming, and porting modes among intelligence, surveillance, and reconnaissance (ISR) platforms is nearly impossible.  The Software-Defined ISR program seeks to improve the utility of existing and emerging sensor and EW systems by enabling rapid development and porting of modes among open-architecture systems and permitting users to efficiently deploy new capabilities to current radar, EW, and ESM systems via software upgrades.  This will allow the Services to leverage investments in mode development by re-using software across different platforms and when platforms are upgraded, while enhancing operational capability by allowing a system to be optimized to the mission.  This program will develop and demonstrate software tools to enable rapid development and porting of ISR modes on open-architecture hardware systems.  Radar, EW, and ESM modes will be developed and demonstrated to pave the way for future development of cognitive radar capabilities, and ported among Open Architecture (OA) compliant ISR systems to build and demonstrate a mode development environment (ModeLab). The key elements of the Software-Defined ISR program are as follows: to develop Hardware Abstraction Layer (HAL) tools to support rapid porting of modes onto open-architecture systems, including the Flexible Open-Architecture Middleware (FOAM) and the ModeLab for rapid mode development; to demonstrate the ability to rapidly develop and port new radar, EW, and ESM modes to open-architecture RF systems; to develop and demonstrate implementation of multiple modes spanning a range of performance and capabilities; and to perform data collections to support mode development.  This program will transition to the Services."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "10.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "10.000"
                                            },
                                            "Text": {
                                                "val": "-  Assemble requirements for FOAM to provide an abstraction of the underlying software and hardware architectures and provide an efficient interface from the mode layer to the radar.\n-  Commence FOAM design.\n-  Assemble requirements for a mode development environment (ModeLab) that can support radar, EW, and ESM functions.\n-  Commence design of ModeLab."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-02"
                    },
                    "ProjectTitle": {
                        "val": "SENSORS AND PROCESSING SYSTEMS"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "102.497"
                        },
                        "CurrentYear": {
                            "val": "105.288"
                        },
                        "BudgetYearOne": {
                            "val": "104.811"
                        },
                        "BudgetYearOneBase": {
                            "val": "104.811"
                        },
                        "BudgetYearTwo": {
                            "val": "91.323"
                        },
                        "BudgetYearThree": {
                            "val": "109.194"
                        },
                        "BudgetYearFour": {
                            "val": "137.188"
                        },
                        "BudgetYearFive": {
                            "val": "147.920"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Sensors and Processing Systems project develops and demonstrates the advanced sensor and processing technologies and systems necessary for intelligence, surveillance, and reconnaissance (ISR) missions.  Future battlefields will continue to be populated with targets that use mobility and concealment as key survival tactics, and high-value targets will range from specific individual insurgents and vehicles to groups of individuals and large platforms such as mobile missile launchers and artillery.  The Sensors and Processing Systems Project is primarily driven by four needs: (a) providing day-night ISR capabilities against the entire range of potential targets; (b) countering camouflage, concealment, and deception of mobile ground targets; (c) detecting and identifying objects of interest\/targets across wide geographic areas in near-real-time; and (d) enabling reliable identification, precision fire control tracking, timely engagement, and accurate battle damage assessment of ground targets.  The Sensors and Processing Systems Project develops and demonstrates technologies and system concepts that combine novel approaches to sensing with emerging sensor technologies and advanced sensor and image processing algorithms, software, and hardware to enable comprehensive knowledge of the battlespace and detection, identification, tracking, engagement, and battle damage assessment for high-value targets in all weather conditions and combat environments."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Behavioral Learning for Adaptive Electronic Warfare (BLADE)"
                                    },
                                    "Description": {
                                        "val": "The Behavioral Learning for Adaptive Electronic Warfare (BLADE) program will develop the capability to jam adaptive and rapidly evolving radio frequency (RF) threats in tactical environments and at tactically-relevant timescales.  This will change the paradigm for responding to evolving threats from lab-based manual development to an adaptive in-the-field systems approach.  When an unknown or advanced RF threat appears, BLADE networked nodes will dynamically characterize the emitter, synthesize an effective countering technique, and evaluate jamming effectiveness by iteratively probing, learning, and adapting to the threat.  An optimization process will tailor real-time responses to specific threats, producing a countermeasure waveform that maximizes jam effectiveness while minimizing the required jamming resources.  Thus BLADE will enable the rapid defeat of new RF threats and provide the warfighter with real-time feedback on jam effectiveness.  The program is planned for transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "16.000"
                                            },
                                            "Text": {
                                                "val": "-  Optimized algorithms for real-time operations and ported to breadboard computing platforms.\n-  Performed construction, integration, and testing of real-time hardware implementation.\n-  Developed threat libraries and testing methodology.\n-  Created transition plan in concert with relevant programs of record and Service partners."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "17.100"
                                            },
                                            "Text": {
                                                "val": "-  Perform test and evaluation of real-time prototypes in a laboratory environment based on Government provided threats.\n-  Extend and enhance algorithms for over-the-air mobile operations in cluttered RF environments.\n-  Demonstrate accurate real-time electronic warfare (EW) battle damage assessment for transition partner defined threats."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "5.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "5.000"
                                            },
                                            "Text": {
                                                "val": "-  Formally test and evaluate prototype systems in an operationally relevant environment.\n-  Quantify the minimum hardware requirements, including processing and memory, necessary to execute the BLADE algorithms on transition platforms."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Adaptive Radar Countermeasures (ARC)"
                                    },
                                    "Description": {
                                        "val": "The goal of the Adaptive Radar Countermeasures (ARC) program is to provide effective electronic countermeasure (ECM) techniques against new or unknown threat radars.  Current airborne electronic warfare (EW) systems rely on the ability to uniquely identify a threat radar system to apply an appropriate preprogrammed countermeasure technique which can take many months to develop.  Countering radar systems is increasingly challenging as digitally programmed radars exhibit novel behaviors and agile waveform characteristics.  ARC will develop new processing techniques and algorithms that adapt in real-time to generate suitable countermeasures.  Using techniques such as state modeling, machine learning, and system probing, ARC will learn the behavior of the threat system, then choose and implement an appropriate countermeasure strategy.  The program is planned for transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "8.041"
                                            },
                                            "Text": {
                                                "val": "-  Developed algorithmic approaches to isolate novel radar signals in the presence of other hostile, friendly, and neutral signals, and to deduce the threat posed by that signal.\n-  Designed high-level system architecture and developed preliminary software application programming interfaces and interface control documents.\n-  Developed preliminary techniques for synthesizing a countermeasure that achieves a desired effect on the threat radar."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "18.221"
                                            },
                                            "Text": {
                                                "val": "-  Complete detailed system architecture design and validate software interfaces.\n-  Conduct offline testing to demonstrate signal analysis and characterization of unanticipated or ambiguous radar signals.\n-  Assess countermeasure effectiveness from over-the-air observable changes in the threat radar signals.\n-  Develop methodologies for closed-loop system testing against adaptive radar threats.\n-  Obtain baseline hardware from transition partners for integration and testing of algorithms in a laboratory environment."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "26.975"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "26.975"
                                            },
                                            "Text": {
                                                "val": "-  Refine and integrate component algorithms for end-to-end system testing in a hardware-in-the-loop laboratory environment.\n- Begin porting software algorithms onto transition partner provided baseline EW systems to demonstrate enhanced performance against unknown or ambiguous threat radars.\n- Develop detailed flight test plans in concert with relevant programs of record and Service partners."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Military Imaging and Surveillance Technology (MIST)"
                                    },
                                    "Description": {
                                        "val": "The Military Imaging and Surveillance Technology (MIST) program is developing a fundamentally new optical Intelligence, Surveillance, and Reconnaissance (ISR) capability that can provide high-resolution 3-D images to locate and identify a target at much longer ranges than is possible with existing optical systems.  Several prototype optical surveillance and observation systems are being developed that: (1) demonstrate probabilities of recognition and identification at distances sufficient to allow stand-off engagement; (2) overcome atmospheric turbulence, which now limits the ability of high-resolution optics; and (3) increase target identification confidence to reduce fratricide and\/or collateral damage.  The program will develop and integrate the necessary component technologies including high-energy pulsed lasers, receiver telescopes that have a field of view and depth of field that obviates the need for steering or focusing the optical system, computational imaging algorithms to improve system resolution, and data exploitation and analysis tools.  Advances in laser systems, digital imagers, and novel image processing algorithms will be leveraged to reduce the overall size, weight, and power (SWaP) of imaging systems to allow for soldier portable and UAV platform integration.  MIST will also continue to integrate technologies developed under the Crosswind Sensor System for Snipers (C-WINS) and the Dynamic Image Gunsight Optics (DInGO) efforts.  MIST will develop an optical rifle scope that enables a soldier, with minimal training, to shoot a firearm with marksman accuracy at range while also enhancing the capability for close quarters combat.  The MIST program will transition the optical ISR technology to the Air Force and SOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "36.455"
                                            },
                                            "Text": {
                                                "val": "-  Completed development of MIST short-range 3-D imaging brassboards.\n-  Completed Preliminary Design Review of the MIST long-range 3-D imaging system for operation on aerial platforms.\n-  Initiated brassboard development and critical design review-level design of long-range MIST 3-D imaging technology.\n-  Demonstrated key technologies to enable operation of MIST 3-D imaging technologies at increased ranges.\n-  Demonstrated a fiber laser system compatible with the MIST long-range platforms.\n-  Completed and transitioned the digital rifle-scope prototypes."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "30.863"
                                            },
                                            "Text": {
                                                "val": "-  Complete and transition the short-range 3-D imaging prototypes and technology to the Services.\n-  Complete brassboard and ground demonstrations of the long-range 3-D imaging systems, including testing and demonstration of critical subsystem components.\n-  Complete packaging of the high-power pulsed laser required for the MIST long-range prototypes.\n-  Commence long-range 3-D imaging prototype design and development.\n-  Develop most promising crosswind sensor technologies.\n-  Develop, test, and transition near-hypervelocity rounds for snipers.\n-  Investigate alternate uses of crosswind sensor technology."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "22.471"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "22.471"
                                            },
                                            "Text": {
                                                "val": "-  Complete prototypes and airborne demonstrations of the long-range 3-D imaging systems, including testing and demonstration.\n-  Transition the long-range MIST systems to the Air Force.\n-  Transition the short-range 3-D imaging prototypes and technology to the Services.\n-  Complete packaging and testing of the flight qualified MIST laser.\n-  Complete prototypes of the long-range 3-D imaging systems.\n-  Conduct airborne testing and demonstrations of the long-range 3-D imaging systems."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multifunction RF"
                                    },
                                    "Description": {
                                        "val": "The Multifunction RF (MFRF) program goal is to enable U.S. rotary wing aircraft forces to fight effectively in all forms of severely Degraded Visual Environments (DVE) when our adversaries cannot.  The program goes beyond landing aids in DVE to address all elements of combat to include landing, takeoff, hover\/taxi, enroute, navigation, lethality, and survivability.  Building on previous RF sensors advancements, the program will seek to eliminate many redundant RF elements of current independently-developed situational and combat support systems to provide multifunction capability with flexibility of adding new mission functions.  This will reduce the overall size, weight, power, and cost (SWaP-C) of subsystems and protrusive exterior antennas on military aircraft, enabling greater mission capability with reduced vehicle system integration burden.  The program approach includes; 1) Development of synthetic vision for pilots that fuses sensor data with high-resolution terrain databases, 2) Development of Advanced Rotary Multifunction Sensor (ARMS), utilizing silicon-based tile arrays, for agile electronically scanning technology at low SWAP-C, 3) Implementation of software development kit to re-define modes as required by mission or platform needs; ease of adding new modes via software without hardware modifications.  Transition is planned to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "27.280"
                                            },
                                            "Text": {
                                                "val": "-  Began laboratory testing of ARMS components suitable for flight testing.\n-  Completed development and laboratory testing of key subsystem technologies for RF waveforms and arrays.\n-  Flight tested synthetic vision avionics backbone with sensor on selected aircraft platform.\n-  Investigated advanced silicon tile designs and array backplanes to improve system size, weight, and power (SWaP)."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "20.354"
                                            },
                                            "Text": {
                                                "val": "-  Finalize tile array and array backplane technology selection for sub-array builds.\n-  Begin fabrications of sub-arrays for ARMS laboratory demo.\n-  Demonstrate integration of silicon-based tile sub-array and digital receiver\/exciter backplane.\n-  Demonstrate radar software development kit suitable for redefining system functions of integrated system."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "14.375"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "14.375"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate utility of software development kit through third party programming.\n-  Complete laboratory testing of ARMS for flight testing.\n-  Conduct laboratory demo with integrated ARMS, synthetic vision backbone, and multifunction software development kit."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Video-rate Synthetic Aperture Radar (ViSAR)"
                                    },
                                    "Description": {
                                        "val": "Recent conflicts have demonstrated the need for close air support by precision attack platforms such as the AC-130J or the MH-60 class helicopters in support of ground forces.  Under clear conditions, targets are easily-identified and engaged quite effectively, but in degraded environments the atmosphere can inhibit traditional optical sensors.  The AC-130J must fly above cloud decks in order to avoid anti-aircraft fire, negating optical targeting sensors.  Similarly, rotary\/wing blades in urban operations generate copious amounts of dust that prevent circling assets from supplying cover fire for ground forces.  The Video-rate Synthetic Aperture Radar (ViSAR) program seeks to develop a real-time spotlight synthetic aperture radar (SAR) imaging sensor that will provide imagery of a region to allow high-resolution fire direction in conditions where optical sensors do not function.  Technology from this program is planned to transition to AFSOC."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "12.221"
                                            },
                                            "Text": {
                                                "val": "-  Initiated hardware design and development of transmitter and receiver components.\n-  Evaluated RF sensor design concepts that will enable high-resolution targeting information through low altitude clouds.\n-  Assessed impacts of various platforms and global weather conditions on targeting performance."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "18.750"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of transmitter and receiver components for sensor demonstration.\n-  Initiate hardware design and development of ViSAR system.\n-  Demonstrate performance of laboratory quality objective transmitter amplifier.\n-  Complete phenomenology models to support system simulations."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "16.990"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "16.990"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of flight-worthy high power amplifier.\n-  Demonstrate the integration of low power transmitter and receiver components into sensor.\n-  Integrate phenomenology data into scene simulator and generate data for demonstration of algorithm performance."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Precision Timing Enabling Cooperative Effects"
                                    },
                                    "Description": {
                                        "val": "Building on technologies developed in the Adaptable Navigation Systems program, budgeted in Project SEN-01, the Precision Timing Enabling Cooperative Effects program will enable precision cooperative effects by developing global time transfer and synchronization systems independent of GPS.  As a corollary to time synchronization, this program will also enable GPS independent positioning to maintain precise time synchronization between collaborating mobile users.  Key attributes of this program are global availability; minimal and low cost infrastructure; anti-jamming capability; and performance equal to or better than GPS through recent advances in cold atom-based clocks and optical time transfer.  Other recent advances show that navigation systems using non-traditional sensors can be rapidly configured to provide accurate positioning, navigation, and timing (PNT) capabilities.  This program will build on these and other PNT technologies, and extend this level of performance to include the underwater environment in addition to surface, indoor, and airborne environments.  Demonstrations on relevant platforms in relevant environments will be used to validate the technology.  This program will transition to the Services, emphasizing platforms that operate in GPS-denied environments."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "9.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "9.000"
                                            },
                                            "Text": {
                                                "val": "-  Begin developing a precision time transfer and synchronization system using cold atom-based clocks.\n-  Begin developing a wireless precision time transfer system that provides GPS-level performance globally with minimal infrastructure.\n-  Begin developing compact, jam-proof PNT sensors that provide better than GPS-level performance.\n-  Demonstrate GPS-independent PNT using non-PNT sensors that are already installed on the platform (e.g., radars, imagers, communications, etc.).\n-  Begin developing a PNT system that is capable of providing GPS-level positioning and timing performance to undersea users from large standoff distances, and plan for demonstrations."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Automatic Target Recognition (ATR) Technology"
                                    },
                                    "Description": {
                                        "val": "Automatic target recognition (ATR) systems provide the capability to detect, identify, and track high value targets from collected sensor data.  Current ATRs are typically designed for specific sensors and static due to pre-programmed target lists and operating mode, limiting mission execution capabilities.  Extending ATR technology to accommodate sensor upgrades or include new emerging targets can be costly and time consuming.  The objective of the ATR Technology program is to develop technologies that reduce operation limitations while also providing significant performance improvements, dramatically reduced development times, and reduced life cycle maintenance costs.  Recent breakthroughs in deep learning, sparse representations, manifold learning, and embedded systems offer promise for dramatic improvements in ATR.  Three core areas the program will focus on are: development of on-line adaptive algorithms that enable performance-driven sensing and ATR; recognition technology that enables rapid incorporation of new targets; and technologies that dramatically reduce required data rates, processing times, and the overall hardware and software footprint of ATR systems.  ATR technology developed under the program is planned for transition to the Services."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "10.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "10.000"
                                            },
                                            "Text": {
                                                "val": "-  Develop modeling and simulation framework for testing and evaluating performance-driven ATR systems.\n-  Establish baseline performance for existing ATR algorithms against challenge problem data sets.\n-  Design and execute a data collection experiment to provide additional data for testing.\n-  Initiate development of advanced algorithms that support signature generalization and reduced signature database complexity."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Advanced Airborne Optical Sensing"
                                    },
                                    "Description": {
                                        "val": "The Advanced Airborne Optical Sensing program developed electro-optical and infrared sensors and processing technologies for aerial platforms.  Significant challenges arose as the result of two warfighting trends.  First, the ever-changing mix of airborne platforms now includes a greater number of smaller UAVs.  Second, the target set is increasingly challenging and now includes vehicles and individual dismounts that operate under foliage and in urban canyons, using camouflage, obscurants, and other means of concealment.  In response to these challenges, the Advanced Airborne Optical Sensing program developed enhanced optical, electro-optical, photonic and other technologies for airborne optical sensing systems.  The remaining effort in this program, HALOE (High Altitude Lidar Operations Experiment), demonstrated, in an operational environment, the full capability of a 3-D imaging system.  HALOE successfully completed the CONUS flight testing phase and was deployed OCONUS for further testing and system checkout to address current and emerging needs of U.S. forces under the direction of commanders in theater during 2011.  The completed HALOE system transitioned to the U.S. Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.500"
                                            },
                                            "Text": {
                                                "val": "High Altitude Lidar Operations Experiment (HALOE)\n-  Developed additional applications for the high performance LIDAR components embedded within the HALOE system to optimize size, weight, and power (SWaP) for alternate platforms.\n- HALOE system successfully transitioned to U.S. Army Geospatial Center."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-03"
                    },
                    "ProjectTitle": {
                        "val": "EXPLOITATION SYSTEMS"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "47.557"
                        },
                        "CurrentYear": {
                            "val": "40.197"
                        },
                        "BudgetYearOne": {
                            "val": "64.071"
                        },
                        "BudgetYearOneBase": {
                            "val": "64.071"
                        },
                        "BudgetYearTwo": {
                            "val": "63.246"
                        },
                        "BudgetYearThree": {
                            "val": "70.880"
                        },
                        "BudgetYearFour": {
                            "val": "74.664"
                        },
                        "BudgetYearFive": {
                            "val": "80.994"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis.  Efforts will focus on difficult ISR environments, for example (a) urban environments with extensive building obscuration, large volumes of civilian traffic, and feature-rich terrain, (b) mountain environments with highly variable terrain elevation, complex local and regional threat networks, and predominantly dismounted adversaries, (c) jungle environments with targets under heavy canopy, animals, and other sources of clutter masking human activity, and (d) maritime and littoral environments where threats now include terrorists, pirates, smugglers, drug traffickers, and other non-traditional adversaries.  The resulting technology will enable operators to more effectively use ISR data in the execution of wide area search, border and road monitoring, high value target tracking, overwatch, and other missions."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Insight"
                                    },
                                    "Description": {
                                        "val": "Insight is developing the next generation multi-intelligence (multi-INT) exploitation and resource management system.  Insight provides new exploitation capabilities through an integrated, standards-based system that is designed for mission flexibility and cross-theater applicability.  Insight will enable detection of threat networks through combination and analysis of information from imaging and non-imaging sensors and other sources.  The technical approach emphasizes model-based correlation, adversary behavior modeling, threat network analysis tools, resource management tools, a unified data management and processing environment, novel exploitation algorithms and analysis methodologies, and tools to integrate human and machine processing, including visualization, hypothesis manipulation, on-line learning, and distributed social intelligence.  Insight development activities leverage both virtual and physical test bed environments.  The virtual test bed enables evaluation of alternative sensor mixes and algorithms under extended operating conditions.  The physical test bed enables live testing under realistic operational conditions using current and next generation sensing and processing systems.  Insight technology development is being coordinated with the following potential transition sponsors: Army Program Executive Office-Intelligence, Electronic Warfare & Sensors, Distributed Common Ground System (DCGS) - Army, Army Intelligence and Security Command, Air Force - Distributed Common Ground Station, and the National Geospatial-Intelligence Agency.  Insight provides a unified architecture for plug-and-play ISR with extensibility to all Services and Combatant Commands, initially CENTCOM, SOCOM, and PACOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "36.842"
                                            },
                                            "Text": {
                                                "val": "-  Performed comprehensive field tests with Army and Marine Corps user and stakeholder communities to validate system operational utility highlighting collection, resource management, and exploitation of data from physical sensors, human sources, and contextual databases.\n-  Demonstrated capabilities including multi-source correlation of vast scale across all information sources; dynamic sensor tasking, cross-cueing and handoff; hypothesis management of uncertain data; and inference management to prioritize and explain abnormal behaviors.\n-  Integrated the Insight system with live pre-deployment training exercises in coordination with DCGS-Army.\n-  Conducted virtual test bed exercises to demonstrate exploitation, resource management, visualization, and simulation capabilities.\n-  Drafted an agreement to transition Insight technology to DCGS-Army.\n-  Provided system integration and field test support for a full field of view real-time wide-area motion imagery (WAMI) tracker which has since deployed to theater via Air Force."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "36.000"
                                            },
                                            "Text": {
                                                "val": "-  Finalize formal transition agreements and transfer technology to DCGS-Army and Air Force DCGS.\n-  Adapt demonstrated capabilities to emerging operational environments including integration of relevant information sources and sensor models.\n-  Augment the reasoning component of the system in support of the mission profiles of emerging operational environments.\n-  Test and mature advanced fusion technologies in live and virtual operational environments.\n-  Tailor component and system level capabilities to specific transition partner objectives."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "48.539"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "48.539"
                                            },
                                            "Text": {
                                                "val": "-  Adapt capabilities to emerging operational environments, to include integration of additional, non-traditional sensors and information sources.\n-  Test and mature advanced analytic and resource management technologies in live and virtual operational environments.\n-  Execute additional live field tests in coordination with military training rotations to demonstrate improvements and maturity of system capabilities in dynamic operational environments.\n-  Deliver integrated capabilities that address key performance parameters of transition partner programs of record aligned with their software release cycles."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Worldwide Intelligence Surveillance and Reconnaissance (WISR)"
                                    },
                                    "Description": {
                                        "val": "The Worldwide Intelligence Surveillance and Reconnaissance (WISR) system will provide ISR capability in denied areas.  The U.S. military has limited capability to obtain airborne ISR observations of many critical problem areas, and overhead observations are limited by sensor resolution, collection timeline, and platform geometry.  However, millions of videos posted worldwide reflect events and areas of interest for national security, and the number is rapidly increasing.  WISR will use ground-level video and still images to produce 3-D and 4-D reconstructions of events and use these reconstructions to code descriptions of dynamic content, rather than focusing on the identification and movement of individual objects and humans in the scene.  WISR constructs will be suitable for describing and differentiating patterns-of-life to reflect local and societal changes.  The program will use this data in support of three missions: intelligence preparation for expeditionary forces entering a new area of operation, reconstruction of significant events worldwide, and battle damage assessment.  These techniques will transition to operational commands and the intelligence community."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "7.215"
                                            },
                                            "Text": {
                                                "val": "-  Created a collection of open source video clips and identified\/quantified differences from military ISR video in terms of metadata, perspective, field of view, and persistence.\n-  Explored the hypothesis that analysis of a video collection at a macroscopic level to characterize crowd behavior is feasible even when tracking all targets is not practical.\n-  Developed a mathematical approach for extremely efficient computation of crowd properties based on density functional theory and demonstrated\/evaluated the approach via simulation."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "4.197"
                                            },
                                            "Text": {
                                                "val": "-  Create techniques for automatically correlating and integrating diverse media types such as still images, videos, audio, and text.\n-  Develop coding methodologies to describe scenes in terms of their macroscopic, non-culturally dependent characteristics."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "5.532"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "5.532"
                                            },
                                            "Text": {
                                                "val": "-  Develop a culturally dependent query engine that allows intelligence analysts to find scenes of relevance to a particular mission analysis."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Battlefield Evidence"
                                    },
                                    "Description": {
                                        "val": "The Battlefield Evidence program will create technologies for searching and fusing diverse types of content and media to derive evidence of adversary activities.  Current approaches to forensics are manpower intensive and require analysts and investigators to undertake painstaking searches of available information and then to manually fuse this information into logical event timelines.  Battlefield Evidence will develop, integrate, and extend text, speech, and video search technologies to provide the relevant spatio-temporal information.  The program will also develop and apply techniques to fuse this information for immersive display to enable human analysts to efficiently and intuitively look for suspicious activities, non-obvious relationships, and other patterns for follow-up.  Battlefield Evidence technologies will transition to operational commands, the intelligence community, and law enforcement agencies."
                                    },
                                    "PlannedProgram": {
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "10.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "10.000"
                                            },
                                            "Text": {
                                                "val": "-  Develop operator-in-the-loop technologies for fusing new types of content and media including open source and intercepted multi-lingual speech and text and other spatio-temporal information.\n-  Design a structured representation language that fuses data from the multiple input sources and highlights inconsistencies for analyst attention.\n-  Initiate development of an immersive capability to walk through and interact with reconstructed environments and events.\n-  Create techniques for representing the level of certainty or confidence in a combined representation."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Wide Area Network Detection (WAND)"
                                    },
                                    "Description": {
                                        "val": "The Wide Area Network Detection (WAND) program developed methods to detect, characterize, and identify threat networks from imaging and other sensors, including national, theater, and organic sensors.  Critical performance metrics are timeliness, accuracy, error rates, and interpretation workload.  The program addressed the challenges of network\/target identification, acquisition, tracking, and denial in difficult environments.  WAND technologies applied advanced signal processing, sensor fusion, and platform control to leverage advances in sensor capabilities.  Technologies developed under the WAND program have transitioned to SOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "3.500"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrated integrated detection of sites, movements, and communications associated with threat network activity.\n-  Demonstrated ability to create accurate wide-area motion imagery (WAMI) tracklets by post processing full field of view airborne video data.\n-  Demonstrated ability to stitch WAMI tracklets into complete origin-to-destination (trip) tracks.\n-  Demonstrated ability to fuse radio frequency (RF) detection data with WAMI tracklet data to improve tracklet stitching accuracy.\n-  Demonstrated integrated analyst-machine processing to improve production efficiency and exploitation accuracy.\n-  Transitioned RF detection system processing algorithms and optimized array to SOCOM."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-06"
                    },
                    "ProjectTitle": {
                        "val": "SENSOR TECHNOLOGY"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "69.673"
                        },
                        "CurrentYear": {
                            "val": "77.550"
                        },
                        "BudgetYearOne": {
                            "val": "88.196"
                        },
                        "BudgetYearOneBase": {
                            "val": "88.196"
                        },
                        "BudgetYearTwo": {
                            "val": "69.946"
                        },
                        "BudgetYearThree": {
                            "val": "45.000"
                        },
                        "BudgetYearFour": {
                            "val": "16.000"
                        },
                        "BudgetYearFive": {
                            "val": "0.000"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds classified DARPA programs that are reported in accordance with Title 10, United States Code, Section 119(a)(1) in the Special Access Program Annual Report to Congress."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Classified DARPA Program"
                                    },
                                    "Description": {
                                        "val": "This project funds Classified DARPA Programs.  Details of this submission are classified."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "69.673"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "77.550"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "88.196"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "88.196"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Details will be provided under separate cover."
                        }
                    }
                }
            ]
        }
    }
}