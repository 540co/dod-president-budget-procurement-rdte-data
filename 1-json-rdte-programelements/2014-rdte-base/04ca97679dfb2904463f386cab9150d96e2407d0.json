{
    "id": "04ca97679dfb2904463f386cab9150d96e2407d0",
    "meta": {
        "filename": "dod-2014_RDTE_2014_DARPA_RDTE_MasterJustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2014.zzz_unzipped_RDTE_MasterJustificationBook_Defense_Advanced_Research_Projects_Agency_PB_2014.xml",
        "budget_year": "2014",
        "budget_cycle": "PB",
        "submission_date": "2013-04",
        "service_agency_name": "Defense Advanced Research Projects Agency",
        "appropriation_code": "0400",
        "appropriation_name": "Research, Development, Test & Evaluation, Defense-Wide"
    },
    "record": {
        "@monetaryUnit": "Millions",
        "ProgramElementNumber": {
            "val": "0603767E"
        },
        "ProgramElementTitle": {
            "val": "SENSOR TECHNOLOGY"
        },
        "R1LineItemNumber": {
            "val": "60"
        },
        "BudgetYear": {
            "val": "2014"
        },
        "BudgetCycle": {
            "val": "PB"
        },
        "SubmissionDate": {
            "val": "2013-04"
        },
        "ServiceAgencyName": {
            "val": "Defense Advanced Research Projects Agency"
        },
        "AppropriationCode": {
            "val": "0400"
        },
        "AppropriationName": {
            "val": "Research, Development, Test & Evaluation, Defense-Wide"
        },
        "BudgetActivityNumber": {
            "val": "3"
        },
        "BudgetActivityTitle": {
            "val": "Advanced Technology Development (ATD)"
        },
        "ProgramElementFunding": {
            "PriorYear": {
                "val": "267.900"
            },
            "CurrentYear": {
                "val": "299.438"
            },
            "BudgetYearOne": {
                "val": "286.364"
            },
            "BudgetYearOneBase": {
                "val": "286.364"
            },
            "BudgetYearTwo": {
                "val": "276.749"
            },
            "BudgetYearThree": {
                "val": "287.424"
            },
            "BudgetYearFour": {
                "val": "283.867"
            },
            "BudgetYearFive": {
                "val": "299.484"
            }
        },
        "ProgramElementMissionDescription": {
            "val": "The Sensors Technology program element is budgeted in the Advanced Technology Development Budget Activity because it funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability and battle damage assessment.  \n\nThe Surveillance and Countermeasures Technology project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing and low-cost microelectronics to develop advanced surveillance and targeting systems.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with tactical information needed to succeed in future wars.  Additionally, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats.  \n\nThe Sensors and Processing Systems project develops and demonstrates the advanced sensor processing technologies and systems necessary for the intelligence surveillance and reconnaissance (ISR) mission.  The project is primarily driven by four needs:  1) providing day-night ISR capabilities against the entire range of potential targets; 2) countering camouflage, concealment and deception of mobile ground targets; 3) detecting and identifying objects of interest\/targets across wide geographic areas in near real-time; and 4) enabling reliable identification, precision fire control, tracking, timely engagement and accurate battle damage assessment of ground targets.\n\nThe Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis."
        },
        "ChangeSummary": {
            "PreviousPresidentBudget": {
                "PriorYear": {
                    "val": "271.802"
                },
                "CurrentYear": {
                    "val": "299.438"
                },
                "BudgetYearOne": {
                    "val": "273.605"
                },
                "BudgetYearOneBase": {
                    "val": "273.605"
                }
            },
            "CurrentPresidentBudget": {
                "PriorYear": {
                    "val": "267.900"
                },
                "CurrentYear": {
                    "val": "299.438"
                },
                "BudgetYearOne": {
                    "val": "286.364"
                },
                "BudgetYearOneBase": {
                    "val": "286.364"
                }
            },
            "TotalAdjustments": {
                "PriorYear": {
                    "val": "-3.902"
                },
                "CurrentYear": {
                    "val": "0.000"
                },
                "BudgetYearOne": {
                    "val": "12.759"
                },
                "BudgetYearOneBase": {
                    "val": "12.759"
                }
            },
            "AdjustmentDetails": {
                "CongressionalGeneralReductions": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedReductions": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalRescissions": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalAdds": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "CongressionalDirectedTransfers": {
                    "PriorYear": {
                        "val": "0.000"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "Reprogrammings": {
                    "PriorYear": {
                        "val": "3.506"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "SBIRSTTRTransfer": {
                    "PriorYear": {
                        "val": "-7.408"
                    },
                    "CurrentYear": {
                        "val": "0.000"
                    }
                },
                "OtherAdjustmentDetailList": {
                    "OtherAdjustmentDetail": [
                        {
                            "Title": {
                                "val": "TotalOtherAdjustments"
                            },
                            "Funding": {
                                "BudgetYearOne": {
                                    "val": "12.759"
                                },
                                "BudgetYearOneBase": {
                                    "val": "12.759"
                                }
                            }
                        }
                    ]
                }
            },
            "SummaryExplanation": {
                "val": "FY 2012:  Decrease reflects the SBIR\/STTR transfer offset by internal below threshold reprogrammings.  \nFY 2014:  Increase reflects expansion of efforts supporting ISR in denied areas."
            }
        },
        "ProjectList": {
            "Project": [
                {
                    "ProjectNumber": {
                        "val": "SEN-01"
                    },
                    "ProjectTitle": {
                        "val": "SURVEILLANCE AND COUNTERMEASURES TECHNOLOGY"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "38.121"
                        },
                        "CurrentYear": {
                            "val": "60.284"
                        },
                        "BudgetYearOne": {
                            "val": "49.538"
                        },
                        "BudgetYearOneBase": {
                            "val": "49.538"
                        },
                        "BudgetYearTwo": {
                            "val": "45.458"
                        },
                        "BudgetYearThree": {
                            "val": "50.458"
                        },
                        "BudgetYearFour": {
                            "val": "55.404"
                        },
                        "BudgetYearFive": {
                            "val": "61.897"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds sensor efforts that will improve the accuracy and timeliness of our surveillance and targeting systems for improved battlefield awareness, strike capability, and battle damage assessment.  Timely surveillance of enemy territory under all weather conditions is critical to providing our forces with the tactical information needed to succeed in future wars.  This operational surveillance capability must continue to perform during enemy efforts to deny and deceive the sensor systems, and operate, at times, in a clandestine manner.  This project will exploit recent advances in multispectral target phenomenology, signal processing, low-power high-performance computing, and low-cost microelectronics to develop advanced surveillance and targeting systems.  In addition, this project encompasses several advanced technologies related to the development of techniques to counter advanced battlefield threats."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Adaptable Navigation Systems (ANS)"
                                    },
                                    "Description": {
                                        "val": "The Adaptable Navigation Systems (ANS) program will provide the U.S. warfighter with the ability to navigate effectively in all environments, including when Global Positioning System (GPS) is unavailable due to hostile action (jamming) or blockage by structures, foliage, or other environmental obstacles.  The ANS approach relies on two major technology innovations.  The first is the use of Signals of Opportunity (SoOp) from a variety of ground, air, and space-based sources.  These will be received on the Services' forthcoming software-defined radios and will use specially tailored algorithms to determine position.  The second technology innovation allows SoOp-based position information to be combined with inertial and other sensors to enable flexible navigation systems that can be reconfigured in the field to support any platform or environment.  While component technology for positioning, navigation, and timing is advancing rapidly (in the form of Micro Electro-Mechanical System devices, clocks, and new aiding sensors), real-time integration and reconfiguration of these components is not possible given today's navigation filters and centralized processing architectures, which are inherently fragile to change.  Recent advances in mathematics, data abstraction, and network architectures could enable \"plug-and-play\" integration of both existing and future navigation components to allow real-time integration and reconfiguration of navigation systems.  If successful, major improvements in navigation accuracy and system cost could also be realized.  Early transition partners would include all Services, with emphasis on platforms and users that must operate in multiple environments."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "13.186"
                                            },
                                            "Text": {
                                                "val": "-  Evaluated candidate filter, sensor, and architecture design for plug-and-play system.\n-  Conducted tests to compare plug-and-play navigation system performance with existing state-of-the-art.\n-  Developed system specification for platform-specific form factor of ANS reference stations.\n-  Demonstrated SoOp-based ranging and navigation.\n-  Built and began testing of first generation 6-degree-of-freedom cold atom-based inertial measurement unit (IMU) in laboratory.\n-  Designed second generation cold atom-based IMU to meet platform-specified size, weight, and power goals and began planning for field testing."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "16.921"
                                            },
                                            "Text": {
                                                "val": "-  Develop and test candidate filter, sensor, and architecture design for plug-and-play system.\n-  Develop ANS reference stations to user-selected platform-specific form factors.\n-  Demonstrate integration of SoOp-based ranging and navigation into ANS systems.\n-  Test and evaluate ANS systems for sea, air, and land-based platforms in GPS-denied mission scenarios.\n-  Field test and evaluate first generation 6-degree-of-freedom cold atom-based IMU.\n-  Begin build of second generation 6-degree-of-freedom cold atom IMU in laboratory."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "13.200"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "13.200"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate flexible, real-time operation of ANS systems on sea, air, and land-based platforms using relevant sensor suites.\n-  Transition novel navigation measurement technologies, via new sensors, algorithms, or measurement enhancements, into ANS demonstration systems.\n-  Evaluate options for Size, Weight, Power and Cost (SWaP-C)-constrained reference stations that enable full SoOp-based navigation.\n-  Complete second generation 6-degree-of-freedom cold atom IMU."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Adaptable, Low Cost Sensors"
                                    },
                                    "Description": {
                                        "val": "The objective of the Adaptable, Low Cost Sensor program is to leverage commercial technology and commercial manufacturing techniques to improve the development time and significantly reduce the cost of sensors and sensor systems.  Military sensors are currently developed as unique designs that fully integrate mission specific hardware required for sensing, with all of the other non-mission specific capabilities, including supporting sensors (GPS), processing, memory storage and communications into a single device.  Not only does this approach significantly increase the cost of the device, it makes changing requirements and the upgrading of any specific component extremely difficult.  Commercial processes, such as those used in the smart phone industry, create reference designs for common system functions and features to accelerate system development time, and make it easier to change requirements and upgrade capability.  Adopting commercial processes makes it possible to create a mission-independent, designed-to-cost \"commercial smart core\" that can be combined with an appliqu\u00e9 of mission-specific hardware to provide the overall sensor system.  The core can be upgraded independently of any particular sensor; sensors can make use of the advances and decreasing cost that is inherent in commercial technology.  Commercial technology can be used in the core and commercial development and manufacturing techniques can also be leveraged to further improve the cost and development time of sensor systems.  In addition, this program will enable effective distributed sensor systems that were previously infeasible due to high cost of individual sensors.  The Smart Munitions effort will use ADAPT's sensing, processing, communications, and location capabilities to provide positive identification and man-in-the-loop control of distributed unattended ground sensor systems.  The Smart Munitions effort will develop a reference design used to demonstrate capability and develop tactics for unattended sensors.  This program will transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "21.346"
                                            },
                                            "Text": {
                                                "val": "-  Manufactured initial version of commercial smart core.\n-  Developed smart core re-usable software and ground mission software.\n-  Defined objectives for distributed sensor systems (ground and UAV) and quantified performance against traditional, non-distributed systems.\n-  Initiated development of a distributed ground sensor systems to be used to evaluate man-in-the-loop control of sensor systems.\n-  Defined objectives for initial field demonstration."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "24.913"
                                            },
                                            "Text": {
                                                "val": "-  Manufacture second version of commercial smart core.\n-  Develop mobile and airborne development kits using the core hardware and software technology.\n-  Refine smart core re-usable software and ground mission software communications, networking, distributed processing, location, and orientation.\n-  Develop and demonstrate Smart Munitions reference design using a ground sensor packaging of the core technology. \n-  Develop image, video detection, tracking, and display utilities to provide positive target identification in support of the Smart Munitions effort."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "11.338"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "11.338"
                                            },
                                            "Text": {
                                                "val": "-  Field test and demonstrate mobile coordinated device operation.\n-  Configure hardware for heterogeneous distributed sensor mission.\n-  Field test heterogeneous distributed sensor mission."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Function Optical Sensor"
                                    },
                                    "Description": {
                                        "val": "The proliferation of radio frequency (RF)-based countermeasures such as digital radio frequency memory (DRFM) has presented challenges to the effectiveness of data sensors.  The Multi-Function Optical Sensing program will provide an alternative approach to detecting, tracking, and performing non-cooperative target identification, as well as providing fire control for fighter class and long-range strike aircraft.  This program leverages emerging high-sensitivity focal plane array (FPA) and compact, multiband laser systems technology in the near\/mid\/long-wave infrared bands to enable the development of a multi-function optical system.  Technical challenges include the demonstration of inexpensive, multiband, large-format, photon-counting, high-bandwidth receivers and their integration into a multi-optical sensor suite compatible with airborne assets.  The Multi-Function Optical Sensor program will result in an airborne system that can detect, geolocate, and identify targets at standoff ranges.  Technologies from this program will transition into the Services."
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "18.450"
                                            },
                                            "Text": {
                                                "val": "-  Initiate development of multiband, high-speed active focal plane arrays.\n-  Initiate development of variable-waveform, high power lasers that demonstrate high wall plug efficiency.\n-  Develop preliminary system architectures for airborne multi-function optical sensors.\n-  Simulate sensor measurements of targets at relevant ranges including the effects of turbulence and atmospheric scattering.\n-  Initiate development of new algorithms and signal processing approaches for effective use of multi-function optical sensing measurements for target tracking and identification.\n-  Investigate the Concept of Operations (CONOPS) for the deployment of a multi-function optical sensor."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "25.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "25.000"
                                            },
                                            "Text": {
                                                "val": "-  Complete design of first-generation prototype sensor through critical design review.\n-  Incorporate results of CONOPS and algorithm performance on simulated data to refine objective system performance requirements.\n-  Initiate the investigation of communications protocols for the multi-optical sensor to interact with other systems and other platforms.\n-  Continue development of sensor data-processing algorithms to improve target tracking and identification.\n-  Initiate advanced system signal-processing methodologies for real-time performance and integration into the second-generation sensor system."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Visibuilding"
                                    },
                                    "Description": {
                                        "val": "The Visibuilding program developed technologies and systems for new building surveillance capabilities to detect personnel within buildings, determine building layouts, and locate weapons caches within buildings.  This program developed techniques to inject and recover probing radar waveforms and unravel the complicated multipath in the return signals to enable the mapping and characterization of building interiors.  Radar signals were used to image static structures directly.  Doppler processing of radar signals was also exploited to find, identify, and perform feature-aided tracking of moving personnel within a building and allow mapping of building pathways and stairways by monitoring traffic through buildings.  Multipath and propagation effects were modeled and iteratively compared with hypotheses of building structures to provide 3-D building maps and large concentrations of metal materials like weapons.  Technologies developed under this program have been made available to the Army and U.S. SOCOM for transition."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "3.589"
                                            },
                                            "Text": {
                                                "val": "-  Transitioned the radar-based prototype to Army and U.S. SOCOM."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-02"
                    },
                    "ProjectTitle": {
                        "val": "SENSORS AND PROCESSING SYSTEMS"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "88.118"
                        },
                        "CurrentYear": {
                            "val": "101.339"
                        },
                        "BudgetYearOne": {
                            "val": "117.233"
                        },
                        "BudgetYearOneBase": {
                            "val": "117.233"
                        },
                        "BudgetYearTwo": {
                            "val": "113.878"
                        },
                        "BudgetYearThree": {
                            "val": "127.078"
                        },
                        "BudgetYearFour": {
                            "val": "133.583"
                        },
                        "BudgetYearFive": {
                            "val": "151.583"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Sensors and Processing Systems project develops and demonstrates the advanced sensor and processing technologies and systems necessary for the intelligence, surveillance, and reconnaissance (ISR) missions.  Future battlefields will continue to be populated with targets that use mobility and concealment as key survival tactics, and high-value targets will range from specific individual insurgents and vehicles to groups of individuals and large platforms such as mobile missile launchers and artillery.  The Sensors and Processing Systems project is primarily driven by four needs: (a) providing day-night ISR capabilities against the entire range of potential targets; (b) countering camouflage, concealment and deception of mobile ground targets; (c) detecting and identifying objects of interest\/targets across wide geographic areas in near-real-time; and (d) enabling reliable identification, precision fire control tracking, timely engagement and accurate battle damage assessment of ground targets.  The Sensors and Processing Systems project develops and demonstrates technologies and system concepts that combine novel approaches to sensing with emerging sensor technologies and advanced sensor and image processing algorithms, software, and hardware to enable comprehensive knowledge of the battlespace and detection, identification, tracking, engagement and battle damage assessment for high-value targets in all weather conditions and combat environments."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Behavioral Learning for Adaptive Electronic Warfare (BLADE)"
                                    },
                                    "Description": {
                                        "val": "The Behavioral Learning for Adaptive Electronic Warfare (BLADE) program will develop the capability to jam adaptive and rapidly evolving radio frequency (RF) threats in tactical environments and at tactically-relevant timescales.  This will change the paradigm for responding to evolving threats from lab-based manual development to an adaptive in-the-field systems approach.  When an unknown or advanced RF threat appears, BLADE networked nodes will dynamically characterize the emitter, synthesize an effective countering technique, and evaluate jamming effectiveness by iteratively probing, learning, and adapting to the threat.  An optimization process will tailor near-real-time responses to specific threats, producing a countermeasure waveform that maximizes jam effectiveness while minimizing the required jamming resources.  Thus BLADE will enable the rapid defeat of new RF threats and provide the warfighter with real-time feedback on jam effectiveness.  The program is planned for transition to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "20.700"
                                            },
                                            "Text": {
                                                "val": "-  Conducted laboratory testing to demonstrate detection and characterization of known and unknown communication signals with sufficient fidelity to meet operational requirements.\n-  Demonstrated the successful offline optimization of jamming waveforms using active probing and learning techniques against communication threats.\n-  Conducted battle damage assessment performance validation via laboratory testing.\n-  Successfully completed Phase 1 end-to-end system performance evaluation on simulation testbed."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "16.000"
                                            },
                                            "Text": {
                                                "val": "-  Optimize algorithms for real-time operations and port to breadboard computing platforms.\n-  Perform construction, integration, and testing of real-time hardware implementation.\n-  Develop threat libraries and testing methodology.\n-  Create transition plan in concert with relevant programs of record and Service partners."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "19.600"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "19.600"
                                            },
                                            "Text": {
                                                "val": "-  Perform test and evaluation of real-time prototypes based on transition partner provided threats.\n-  Begin implementation to form\/fit hardware platform selected by transition partner."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Adaptive Radar Countermeasures (ARC)*"
                                    },
                                    "Description": {
                                        "val": "*Previously part of Behavioral Learning for Adaptive Electronic Warfare (BLADE)\n\nThe goal of the Adaptive Radar Countermeasures (ARC) program is to provide effective electronic countermeasure (ECM) techniques against new or unknown threat radars.  Current airborne electronic warfare (EW) systems rely on the ability to uniquely identify a threat radar system to apply an appropriate preprogrammed countermeasure (CM) technique which can take many months to develop.  Countering radar systems is increasingly challenging as digitally programmed radars exhibit novel behaviors and agile waveform characteristics.  ARC will develop new processing techniques and algorithms that adapt in real-time to generate suitable countermeasures.  Using techniques such as state modeling, machine learning, and system probing, ARC will learn the behavior of the threat system, then choose and implement an appropriate countermeasure strategy.  ARC technologies will transition to the U.S. Air Force and Navy."
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "8.041"
                                            },
                                            "Text": {
                                                "val": "-  Develop algorithms to isolate novel radar signals in the presence of other hostile, friendly, and neutral signals, and deduce the threat posed by that signal.\n-  Design system architecture and develop preliminary software application programming interfaces and interface control documents.\n-  Develop techniques for synthesizing a countermeasure that achieves a desired effect on the threat radar."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "16.300"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "16.300"
                                            },
                                            "Text": {
                                                "val": "-  Complete detailed ARC system architecture design and validate software interfaces.\n-  Conduct offline testing to demonstrate signal analysis and characterization of unanticipated or ambiguous radar signals.\n-  Demonstrate accurate assessment of countermeasure effectiveness from over-the-air observable changes in the threat radar signals.\n-  Develop methodologies for closed-loop ARC system testing against adaptive radar threats."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Military Imaging and Surveillance Technology (MIST)"
                                    },
                                    "Description": {
                                        "val": "The Military Imaging and Surveillance Technology (MIST) program will develop a fundamentally new optical Intelligence Surveillance and Reconnaissance (ISR) capability that can provide high-resolution 3-D images to locate and identify a target at much longer ranges than is possible with existing optical systems.  Several prototype optical surveillance and observation systems will be developed that will: (1) demonstrate probabilities of recognition and identification at distances sufficient to allow stand-off engagement; (2) overcome atmospheric turbulence, which now limits the ability of high-resolution optics; and (3) increase target identification confidence to reduce fratricide and\/or collateral damage.  The program will develop and integrate the necessary component technologies including high-energy pulsed lasers, receiver telescopes that have a field of view and depth of field that obviates the need for steering or focusing the optical system, computational imaging algorithms to improve system resolution, and data exploitation and analysis tools.  Advances in laser systems, digital imagers, and novel image processing algorithms will be leveraged to reduce the overall size, weight and power of imaging systems to allow for soldier portable and UAV platform integration.  MIST will also continue to integrate technologies developed under the Crosswind Sensor System for Snipers (C-WINS) and the Dynamic Image Gunsight Optics (DInGO) efforts.  MIST will develop an optical rifle scope that enables a soldier, with minimal training, to shoot a firearm with marksman accuracy at range while also enhancing the capability for close quarters combat.  The MIST program will transition the optical ISR technology to the Air Force, and SOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "31.159"
                                            },
                                            "Text": {
                                                "val": "-  Completed designs and demonstration of an advanced, high-power pulsed fiber laser system with a size, weight, and power that is suitable for integration on a small or persistent airborne platform.\n-  Completed a Critical Design Review (CDR) level design for the MIST short-range 3-D imaging system.  \n-  Completed a brassboard demonstration of MIST short-range imaging designs that incorporates computational imaging and 3-D digital holographic imaging techniques to achieve the short range performance metrics.\n-  Completed development of two quarter-scale MIST 3-D imaging demonstrator prototypes.\n-  Began integrating the high peak-power pulsed laser technology to increase the operating distance of the MIST 3-D imaging effort.\n-  Began development of the MIST short-range 3-D imaging prototype for surveillance and identification applications.\n-  Began to develop designs to extend the MIST operating range for aerial platforms.\n-  Ported algorithms from a Colfax processor to a mini processor board that is camera independent.\n-  Began development of rifle mount crosswind sensor system.\n-  Evaluated rifle mounted crosswind sensor technologies.\n-  Designed and developed a near-hypervelocity round for snipers."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "35.955"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of MIST short-range 3-D imaging prototypes.\n-  Complete Preliminary Design Review of the MIST 3-D long-range imaging system for operation on aerial platforms.\n-  Initiate brassboard development and CDR-level design of long-range MIST 3-D imaging technology.\n-  Demonstrate key technologies to enable operation of MIST 3-D imaging technologies at increased ranges.\n-  Demonstrate a fiber laser system compatible with the MIST-long range platforms.\n-  Complete development of and test near-hypervelocity round for snipers.\n-  Transition the near-hypervelocity round.\n-  Investigate the use of crosswind sensor technology to ground and airborne applications."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "35.811"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "35.811"
                                            },
                                            "Text": {
                                                "val": "-  Transition the short-range 3-D imaging prototypes and technology to the Services. \n-  Complete brassboard demonstrations of the long-range 3-D imaging systems, including testing and demonstration of critical subsystem components.\n-  Commence long range 3-D imaging prototype design and development.\n-  Develop most promising crosswind sensor technologies identified for ground and airborne applications."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multifunction RF"
                                    },
                                    "Description": {
                                        "val": "The Multifunction RF (MFRF) program initially developed a helicopter pilot performance enhancement system for landing in degraded visual environments (DVE) such as dust clouds.  Beyond landing aids in DVE, RF-based sensors can also be used for additional situational awareness, such as near ground obstacle avoidance, air-to-air collision avoidance, targeting\/fire control, as well as many other combat support activities.  Building on advancements made with RF sensors under this program, the program will further seek to eliminate many redundant RF elements of current independently-developed systems for landing in DVEs, terrain avoidance, obstacle avoidance, and targeting\/fire control.  This will reduce the overall weight, power usage, cost, and profusion of subsystems and exterior antennas on military aircraft, thus enabling greater mission capability with reduced vehicle system integration burden.  Transition is planned to the Services."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "15.800"
                                            },
                                            "Text": {
                                                "val": "-  Initiated hardware design and development of MFRF system for advanced DVE sensor and lethality functions.\n-  Completed initial demonstration of advanced silicon tile for electronically scanned antenna for Multifunction RF sensor.\n-  Defined universal synthetic vision interface and demonstrated synthetic vision system in laboratory tests."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "26.862"
                                            },
                                            "Text": {
                                                "val": "-  Begin laboratory testing of advanced DVE sensor suitable for flight testing.\n-  Complete development and laboratory testing of key subsystem technologies for multifunction RF waveforms and arrays.\n-  Flight test synthetic vision avionics backbone with Government Furnished Equipment sensor on selected aircraft platform.\n-  Investigate advanced silicon tile designs and array backplanes to improve system Size, Weight, and Power (SWaP)."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "26.772"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "26.772"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrate silicon based sub-array integrated with digital receiver\/exciter.\n-  Complete laboratory testing of advanced DVE sensor suitable for flight testing.\n-  Demonstrate radar Software Development Kit suitable for redefining system functions of MFRF sensor.\n-  Complete development and laboratory demonstration of MFRF sensor integrated with multifunction software development kit."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Video-rate Synthetic Aperture Radar (ViSAR)"
                                    },
                                    "Description": {
                                        "val": "Recent conflicts have demonstrated the need for close air support by precision attack platforms such as the AC-130J or the MH-60 class helicopters in support of ground forces.  Under clear conditions, targets are easily-identified and engaged quite effectively, but in degraded environments the atmosphere is not always clear, and inhibits traditional optical sensors.  The AC-130J must fly above cloud decks in order to avoid anti-aircraft fire, and this negates optical targeting sensors.  Similarly, rotary\/wing blades in urban operations generate copious amounts of dust that block circling assets from supplying cover fire for ground forces.  The Video-rate Synthetic Aperture Radar (ViSAR) program will develop a real-time spotlight synthetic aperture radar (SAR) imaging sensor that will provide imagery of a region to allow high-resolution fire direction in conditions where optical sensors do not function.  Technology from this program is planned to transition to AFSOC."
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "11.981"
                                            },
                                            "Text": {
                                                "val": "-  Initiate hardware design and development of transmitter and receiver components.\n-  Evaluate RF sensor design concepts that will enable high-resolution targeting information through low altitude clouds.\n-  Assess impacts of various platforms and global weather conditions on targeting performance."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "18.750"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "18.750"
                                            },
                                            "Text": {
                                                "val": "-  Complete development of transmitter and receiver components for sensor demonstration.\n-  Initiate hardware design and development of ViSAR system.\n-  Demonstrate performance of laboratory quality objective transmitter amplifier.\n-  Complete phenomenology models to support system simulations."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Advanced Airborne Optical Sensing"
                                    },
                                    "Description": {
                                        "val": "The Advanced Airborne Optical Sensing program is developing electro-optical and infrared sensors and processing technologies for aerial platforms.  Significant challenges have arisen as the result of two warfighting trends.  First, the ever-changing mix of airborne platforms now includes a greater number of smaller UAVs.  Second, the target set is increasingly challenging and now includes vehicles and individual dismounts that operate under foliage and in urban canyons, using camouflage, obscurants, and other means of concealment.  In response to these challenges, the Advanced Airborne Optical Sensing program has developed enhanced optical, electro-optical, photonic and other technologies for airborne optical sensing systems.  Specific examples of these technologies include: embedded image processors tailored to real-time detection, identification, and tracking of military targets; advanced laser radar technologies; hyper-spectral sensing technologies; flash detection and underwater object detection; advanced digital signal processing to support onboard image reconstruction, atmospheric correction, and system calibration; and adaptive optics techniques, such as deformable mirrors and liquid crystal spatial light modulators.  The program has extended these technologies and is making them practical for airborne surveillance systems. The remaining effort in this program is the HALOE (High Altitude Lidar Operations Experiment) program which has demonstrated, in an operational environment, the full capability of a 3-D imaging system.  The HALOE system provides support for current and emerging warfighter needs by delivering high-resolution, wide-area 3-D lidar imagery data in the Outside Continental United States (OCONUS) environment.  This system provides the unprecedented capability to collect accurate, high resolution 3-D data over wide areas to support a wide range of high-value applications, including detailed mission planning, vertical obstruction detection, helicopter landing zone analysis, and imagery geolocation.  The pathway to accomplish this goal includes improving the robustness and reliability of the sensor, conducting demonstrations, and training with CONUS flight tests leading to OCONUS operational experimentation in partnership with the Army.\n\nHALOE successfully completed the CONUS flight testing phase and was deployed OCONUS for further testing and system checkout to address current and emerging needs of U.S. forces under the direction of commanders in theater during 2011.  The completed HALOE system will transition to the U.S. Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "8.809"
                                            },
                                            "Text": {
                                                "val": "High Altitude Lidar Operations Experiment (HALOE)\n-  Explored additional applications for the high performance LIDAR components embedded within the HALOE system to optimize size, weight, and power for alternate platforms."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "2.500"
                                            },
                                            "Text": {
                                                "val": "High Altitude Lidar Operations Experiment (HALOE)\n-  Develop additional applications for the high performance LIDAR components embedded within the HALOE system to optimize size, weight, and power for alternate platforms."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Autonomous Real-time Ground Ubiquitous Surveillance (ARGUS)"
                                    },
                                    "Description": {
                                        "val": "The Autonomous Real-time Ground Ubiquitous Surveillance (ARGUS) program developed airborne sensor systems that provide a persistent, real-time, high-resolution, wide-area, day-night video surveillance capability.  The ARGUS Infrared System (ARGUS-IR) uses an advanced infrared (IR) composite focal plane array (FPA) sensor.  The nighttime persistent capability provided by ARGUS-IR combined with the daytime capability provided by the ARGUS Imaging System (ARGUS-IS) enables 24-hour day\/night surveillance.  ARGUS-IR's wide-area, high-update-rate, high-resolution imaging capability enables detection and tracking of dismounts as well as vehicles.  ARGUS-IR utilizes the signal\/image processor developed as part of ARGUS-IS, enabling ARGUS-IS and ARGUS-IR to be combined on a common platform.  ARGUS-IR must overcome a number of demanding technical challenges related to the IR FPA and size, weight, and power constraints for the IR sensor.  A transition plan is being developed with the U.S. Air Force and U.S. Army."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "11.650"
                                            },
                                            "Text": {
                                                "val": "-  Catastrophic mechanical failure of the A-160 aircraft during operational testing precluded the planned transition of the ARGUS-IS to the Army under the ARMY\/ARGUS-IS\/A-160 (AAA) Quick Reaction Capability (QRC) initiative.\n-  Worked with the Army to integrate ARGUS-IS onto other manned and unmanned platforms to support other QRC initiatives.\n-  Integrated the IR sensor into the gimbal.\n-  Completed interface control documentation to integrate the IR sensor and airborne processing system onto the YEH-60 Blackhawk helicopter for engineering and developmental training."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-03"
                    },
                    "ProjectTitle": {
                        "val": "EXPLOITATION SYSTEMS"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "78.969"
                        },
                        "CurrentYear": {
                            "val": "63.119"
                        },
                        "BudgetYearOne": {
                            "val": "65.093"
                        },
                        "BudgetYearOneBase": {
                            "val": "65.093"
                        },
                        "BudgetYearTwo": {
                            "val": "70.413"
                        },
                        "BudgetYearThree": {
                            "val": "76.888"
                        },
                        "BudgetYearFour": {
                            "val": "82.880"
                        },
                        "BudgetYearFive": {
                            "val": "86.004"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "The Exploitation Systems project develops algorithms, software, and information processing systems to extract information from massive intelligence, surveillance, and reconnaissance (ISR) datasets.  In particular, it develops new technologies for detection and discrimination of targets from clutter, classification and fingerprinting of high value targets, localization and tracking over wide areas, and threat network identification and analysis.  Efforts will focus on difficult ISR environments, for example (a) urban environments with extensive building obscuration, large volumes of civilian traffic, and feature-rich terrain, (b) mountain environments with highly variable terrain elevation, complex local and regional threat networks, and predominantly dismounted adversaries, (c) jungle environments with targets under heavy canopy, animals, and other sources of clutter masking human activity, and (d) maritime and littoral environments where threats now include terrorists, pirates, smugglers, drug traffickers, and other non-traditional adversaries.  The resulting technology will enable operators to more effectively use ISR data in the execution of wide area search, border and road monitoring, high value target tracking, overwatch, and other missions."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Insight"
                                    },
                                    "Description": {
                                        "val": "Insight is developing the next generation multi-intelligence (multi-INT) exploitation and resource management system.  Insight provides new exploitation capabilities through an integrated, standards-based system that is designed for mission flexibility and cross-theater applicability.  Insight will enable detection of threat networks through combination and analysis of information from imaging and non-imaging sensors and other sources.  The technical approach emphasizes model-based correlation, adversary behavior modeling, threat network analysis tools, resource management tools, a unified data management and processing environment, novel exploitation algorithms and analysis methodologies, and tools to integrate human and machine processing, including visualization, hypothesis manipulation, on-line learning, and distributed social intelligence.  Insight development activities leverage both virtual and physical test bed environments.  The virtual test bed enables evaluation of alternative sensor mixes and algorithms under extended operating conditions.  The physical test bed enables live testing under realistic operational conditions using current and next generation sensing and processing systems.  Insight technology development is being coordinated with the following potential transition sponsors: Army Program Executive Office-Intelligence, Electronic Warfare & Sensors, Distributed Common Ground System - Army, Army Intelligence and Security Command, Air Force - Distributed Common Ground Station, and the National Geospatial-Intelligence Agency.  Insight provides a unified architecture for plug-and-play ISR with extensibility to all Services and Combatant Commands, initially USCENTCOM, USSOCOM, and USPACOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "50.205"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrated the baseline multi-source exploitation, collection, and resource management system and human-machine interface techniques against user-validated operational use cases, scenarios, and concepts of operation (CONOPs) in both physical and virtual test bed environments.\n-  Established a virtual test bed for baseline testing of system scalability and fidelity, and analysis of alternative CONOPs.\n-  Populated a developmental database with additional operationally diverse, real-world collected data to support rapid prototyping of innovative exploitation, resource management, and analytical tools.\n-  Evaluated multi-INT sensor exploitation and control techniques in the virtual test bed.\n-  Conducted a series of increasingly complex system integration demonstrations to validate architectural design leading to the first end-to-end system demonstration.\n-  Performed a limited field test at the physical test bed to demonstrate unique system functionality, component interoperability, data flow, usability, and operational impact."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "45.000"
                                            },
                                            "Text": {
                                                "val": "-  Conduct system integration demonstrations of functionality and performance.\n-  Perform comprehensive field tests with user and stakeholder communities to validate system operational utility highlighting collection and resource management and exploitation of data from physical sensors, human sources, and contextual databases.\n-  Demonstrate capabilities including multi-source correlation of vast scale across all information sources; dynamic sensor tasking, cross-cueing and handoff; hypothesis management of uncertain data; and inference management to prioritize and explain abnormal behaviors.\n-  Integrate the Insight system with live pre-deployment training exercises in coordination with transition partners.\n-  Demonstrate the ability of the system to adapt to expanding missions and evolving tactical and operational environments.\n-  Transition technologies to fill key capability gaps and technology shortfalls for existing programs of record.\n-  Conduct virtual test bed exercises to demonstrate exploitation, resource management, visualization, and simulation capabilities.\n-  Demonstrate mature capabilities in live and virtual environments for transition partners.\n-  Transition initial technologies and capabilities to Service partners."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "45.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "45.000"
                                            },
                                            "Text": {
                                                "val": "-  Adapt demonstrated capabilities to emerging operational environments including integration of relevant information sources and sensor models, both existing and emerging.\n-  Augment the reasoning component of the system in support of the mission profiles of emerging operational environments.\n-  Integrate other maturing information technologies and programs.\n-  Demonstrate the initial end-to-end system in live and virtual operational environments.\n-  Tailor component and system level capabilities to specific transition objectives."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Wide Area Network Detection (WAND)"
                                    },
                                    "Description": {
                                        "val": "The Wide Area Network Detection (WAND) program is developing methods to detect, characterize, and identify threat networks from imaging and other sensors, including national, theater, and organic sensors.  Critical performance metrics are timeliness, accuracy, error rates, and interpretation workload.  The program addresses the challenges of network\/target identification, acquisition, tracking, and denial in difficult environments.  WAND technologies apply advanced signal processing, sensor fusion, and platform control to leverage advances in sensor capabilities.  Transition is planned to the Air Force, Army, SOCOM, and National Geospatial - Intelligence Agency (NGA)."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "20.874"
                                            },
                                            "Text": {
                                                "val": "-  Conducted live-fly data collection to obtain time-coincident wide-area motion imagery (WAMI) and RF detection data.\n-  Completed fabrication and testing of back-end WAMI processor.\n-  Demonstrated improvement in RF geolocation accuracy and transitioned enhanced RF sensor capability to SOCOM.\n-  Demonstrated forensic coincident exploitation of WAMI and RF detection data collected at CONUS test site (Trident Spectre 2012)."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "10.619"
                                            },
                                            "Text": {
                                                "val": "-  Integrate and demonstrate techniques on Insight testbed.\n-  Demonstrate live processing of time-coincident WAMI and RF detection data at CONUS test site.\n-  Demonstrate integrated detection of sites, movements, and communications associated with threat network activity.\n-  Demonstrate ability to create accurate WAMI tracks in real time."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "6.000"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "6.000"
                                            },
                                            "Text": {
                                                "val": "-  Deliver prototype multi-entity geospatial activity correlator to NGA and U.S. Air Force.\n-  Transition prototype Gen-2 WAMI processor to U.S. Air Force."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Worldwide Intelligence Surveillance and Reconnaissance (WISR)"
                                    },
                                    "Description": {
                                        "val": "The Worldwide Intelligence Surveillance and Reconnaissance (WISR) system will provide ISR capability in denied areas.  The U.S. military has limited capability to obtain airborne ISR observations of many critical problem areas, and overhead observations are limited by sensor resolution, collection timeline, and platform geometry.  However, millions of videos posted worldwide reflect events and areas of interest for national security, and the number is rapidly increasing.  WISR will use ground-level video and still images to produce 3-D and 4-D reconstructions of events and use these reconstructions to code descriptions of dynamic content, rather than focusing on the identification and movement of individual objects and humans in the scene.  WISR constructs will be suitable for describing and differentiating patterns-of-life to reflect local and societal changes. The program will use this data in support of three missions: intelligence preparation for expeditionary forces entering a new area of operation, reconstruction of significant events worldwide, and battle damage assessment. These techniques will transition to operational commands and the intelligence community."
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "7.500"
                                            },
                                            "Text": {
                                                "val": "-  Develop and implement techniques for automatically locating and extracting relevant videos and images in a particular area.\n-  Create image understanding techniques to place videos in geographic and chronological context, perform 4-D reconstruction of events, and code the reconstructions based on the dynamic macro-level content of the reconstructions.\n-  Apply image understanding techniques to interpret those reconstructions and videos that meet operator-specified criteria for significant intelligence content."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "14.093"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "14.093"
                                            },
                                            "Text": {
                                                "val": "-  Create techniques for automatically correlating and integrating diverse media types such as still images, videos, audio, and text.\n-  Develop and prototype coding methodologies to describe video scenes in terms of their macroscopic, non-culturally dependent characteristics.\n-  Develop and prototype culturally dependent query engines that allow intelligence analysts to combine sequenced and non-sequenced combinations of macroscopic characteristics to find scenes of relevance to a particular mission analysis."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Multi-Sensor Exploitation"
                                    },
                                    "Description": {
                                        "val": "The Multi-Sensor Exploitation program provided multi-sensor exploitation capabilities enabling missions such as overwatch, border surveillance, high value target tracking, and threat network detection using mixes of imaging, radar, signals, human intelligence, and other sources.  New processing techniques for hyperspectral imaging sensors enabled long duration tracking of vehicles and dismounts.  Scalable stochastic modeling and inference techniques yielded improved situation awareness and assessment for wide-area electro-optical\/IR motion imaging, radar, and multi-sensor exploitation applications in settings where large numbers of interacting entities engaged in complex activities are observed over long periods of time.  The techniques are intended for use in riverine and maritime environments, where extremist and criminal groups threaten political stability, trade routes, and free commerce, map navigable tributary systems, detect and identify threats, and monitor their activity.  Potential transition partners include USAFRICOM, USSOUTHCOM, USSOCOM, and intelligence agencies."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "2.690"
                                            },
                                            "Text": {
                                                "val": "-  Demonstrated flow-based tracker improvements using instrumented data and in-theater data.  \n-  Developed techniques to compensate for complex atmospheric phenomena and demonstrated capability to detect\/track vehicles using airborne longwave infrared (LWIR) hyperspectral data. \n-  Developed and demonstrated LWIR hyperspectral capability for chemical tag detection and ground-based detection of chemical materials of interest on vehicles.  \n-  Coordinated results and planned the development of a deployable ground-based prototype (for checkpoint interdiction) with transition partner.  \n-  Transitioned the atmospheric downwelling correction algorithms and the sub-pixel detection algorithms into NGA's operational exploitation configuration."
                                            }
                                        }
                                    }
                                },
                                {
                                    "Title": {
                                        "val": "Foliage Penetrating Radar Planning and Exploitation"
                                    },
                                    "Description": {
                                        "val": "The Foliage Penetrating Radar Planning and Exploitation program developed and integrated exploitation capabilities that find and track dismounted targets in densely forested terrain.  Current foliage penetrating radar systems provide an important capability for detecting dismount targets under foliage, but the systems also detect animals, moving water, blowing trees, and other scene clutter moving under or in the foliage that make situation assessment manpower and radar resource intensive.  This program addressed these issues by (1) developing algorithms that exploit Doppler signature data to classify detections as dismounts, animals, clutter, or vehicles; and (2) developing group tracking software that automatically tracks groups of dismounts and provides an accurate group size (\"raid count\") to users.  The Doppler discriminator and group tracking software were integrated into a stand-alone exploitation system which provides a significantly improved capability for finding and localizing targets under foliage, as well as providing automatic raid count and human\/vehicle\/animal\/clutter classification.  The program is transitioning to USSOUTHCOM and USSOCOM."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "5.200"
                                            },
                                            "Text": {
                                                "val": "-  Refined and tested algorithms for performing Doppler discrimination and assessing group state and activity.\n-  Designed and implemented a dismount exploitation architecture that combines the Doppler discriminator and group state estimator modules and demonstrated performance in the laboratory.\n-  Integrated Doppler discriminator and group state tracker into a stand-alone exploitation cell at the U.S. Army Communications-Electronics RD&E Center Intelligence and Information Warfare Directorate (CERDEC I2WD)."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Specific programmatic performance metrics are listed above in the program accomplishments and plans section."
                        }
                    }
                },
                {
                    "ProjectNumber": {
                        "val": "SEN-06"
                    },
                    "ProjectTitle": {
                        "val": "SENSOR TECHNOLOGY"
                    },
                    "SpecialProject": {
                        "val": "0"
                    },
                    "ProjectFunding": {
                        "PriorYear": {
                            "val": "62.692"
                        },
                        "CurrentYear": {
                            "val": "74.696"
                        },
                        "BudgetYearOne": {
                            "val": "54.500"
                        },
                        "BudgetYearOneBase": {
                            "val": "54.500"
                        },
                        "BudgetYearTwo": {
                            "val": "47.000"
                        },
                        "BudgetYearThree": {
                            "val": "33.000"
                        },
                        "BudgetYearFour": {
                            "val": "12.000"
                        },
                        "BudgetYearFive": {
                            "val": "0.000"
                        }
                    },
                    "R2aExhibit": {
                        "ProjectMissionDescription": {
                            "val": "This project funds classified DARPA programs that are reported in accordance with Title 10, United States Code, Section 119(a)(1) in the Special Access Program Annual Report to Congress."
                        },
                        "AccomplishmentPlannedProgramList": {
                            "AccomplishmentPlannedProgram": [
                                {
                                    "Title": {
                                        "val": "Classified DARPA Program"
                                    },
                                    "Description": {
                                        "val": "This project funds Classified DARPA Programs.  Details of this submission are classified."
                                    },
                                    "Accomplishment": {
                                        "PriorYear": {
                                            "Funding": {
                                                "val": "62.692"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    },
                                    "PlannedProgram": {
                                        "CurrentYear": {
                                            "Funding": {
                                                "val": "74.696"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        },
                                        "BudgetYearOne": {
                                            "Funding": {
                                                "val": "54.500"
                                            }
                                        },
                                        "BudgetYearOneBase": {
                                            "Funding": {
                                                "val": "54.500"
                                            },
                                            "Text": {
                                                "val": "Details will be provided under separate cover."
                                            }
                                        }
                                    }
                                }
                            ]
                        },
                        "PerformanceMetrics": {
                            "val": "Details will be provided under separate cover."
                        }
                    }
                }
            ]
        }
    }
}